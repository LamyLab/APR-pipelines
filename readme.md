Welcome to `pAPRica` (Pipelines for Adaptive Particle Representation Image Compositing and Analysis), a package based on Adaptive Particle Representation (APR) to accelerate
image processing and research involving imaging and microscopy.

<center>
<img src=./doc/images/pipeline_pv.png title="pipeline image" width="650"/>
</center>

`pAPRica` was built on:

- [LibAPR](https://github.com/AdaptiveParticles/LibAPR): the C++ backbone library
- [pyapr](https://github.com/AdaptiveParticles/pyapr/): a python wrapper for LibAPR including unique features

For more information on usage, examples and notebooks, check our documentation.

Briefly, `pAPRica` allows to accelerate image processing for volumetric data-sets while lowering the hardware requirements. It
is made of several independent modules that are tailored to convert, stitch, segment, map to an atlas and visualize
data. `pAPRica` can work as a postprocessing tool and is also compatible with real time usage during acquisitions, 
enabling minimal lead time between imaging and analysis.

# Requirements

`pAPRica` is only available for Linux at the moment. There are no limitations to port it to Windows and Mac and you
are welcome to contact us. It should run on any computer, it's best if the RAM is 3 times the size of a 
single tile.

# How to install

- Download from the repo
- `cd` into the folder
- run `pip install -e .`

# Be part of the community

To report bugs and code issues :beetle:: please open an [issue](https://github.com/WyssCenter/APR-pipelines/issues)

# References:

If you use this pipeline for your research, please consider citing the following:

- ArXiv preprint of the paper
- [Adaptive particle representation of fluorescence microscopy images](https://www.nature.com/articles/s41467-018-07390-9): original implementation of APR published in Nature Communications.

# How to build documentation

The documentation is automatically generated by GitHub workflows when committing to the *master* branch and deployed on
*gh-pages* branch. When the repo is turned public, it will be published automatically. 

Alternatively the documentation can be generated locally, first `cd` into the documentation folder:

`cd doc`

Then run:

`make html` (linux) or `make.bat html` (windows)

# Tests

To run test locally:

`python -m pytest --import-mode=append tests/`

Tests are also run automatically on GitHub workflows for each pull request.
