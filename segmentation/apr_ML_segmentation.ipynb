{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pyapr\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def are_labels_the_same(local_labels):\n",
    "    labels = local_labels[local_labels != 0].flatten()\n",
    "    return ((labels == labels[0]).all(), labels[0])\n",
    "\n",
    "\n",
    "# APR file to segment\n",
    "fpath_apr = r'/media/sf_shared_folder_virtualbox/mouse_2P/data1/2P_mouse_re0.2.apr'\n",
    "fpath_labels = r'/media/sf_shared_folder_virtualbox/mouse_2P/data1/manual_sparse_labels_membrane.npy'\n",
    "\n",
    "# Instantiate APR and particle objects\n",
    "apr = pyapr.APR()\n",
    "parts = pyapr.ShortParticles()  # input particles can be float32 or uint16\n",
    "labels = np.load(fpath_labels).squeeze().astype('uint16') # 0: not labeled - 1: cells - 2: background\n",
    "\n",
    "# Read from APR file\n",
    "pyapr.io.read(fpath_apr, apr, parts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform segmentation on APR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous label detected, set it to 0.\n",
      "Ambiguous label detected, set it to 0.\n",
      "Ambiguous label detected, set it to 0.\n",
      "Ambiguous label detected, set it to 0.\n",
      "Ambiguous label detected, set it to 0.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over APR structure to obtain level\n",
    "apr_it = apr.iterator()\n",
    "org_dims = apr.org_dims()  # dimension order (y, x, z)\n",
    "py_recon = np.empty((org_dims[2], org_dims[1], org_dims[0]), dtype=np.uint16)\n",
    "max_level = apr.level_max()\n",
    "\n",
    "# particles at the maximum level coincide with pixels so we just assign the label\n",
    "parts_train_C = pyapr.ShortParticles()\n",
    "pyapr.io.read(fpath_apr, apr, parts_train_C)\n",
    "parts_train = np.array(parts_train_C, copy=False)\n",
    "# Read from APR file\n",
    "pyapr.io.read(fpath_apr, apr, parts)\n",
    "lvl = np.empty_like(parts_train)\n",
    "for z in range(apr_it.z_num(apr.level_max())):\n",
    "    for x in range(apr_it.x_num(apr.level_max())):\n",
    "        for idx in range(apr_it.begin(apr.level_max(), z, x), apr_it.end()):\n",
    "            parts_train[idx] = labels[z, x, apr_it.y(idx)]\n",
    "\n",
    "\n",
    "# loop over levels up to level_max-1 to assign the remaining labels\n",
    "for level in range(apr_it.level_min(), apr_it.level_max()):\n",
    "    step_size = 2 ** (max_level - level)    # this is the size (in pixels) of the particle cells at level\n",
    "    for z in range(apr_it.z_num(level)):\n",
    "        for x in range(apr_it.x_num(level)):\n",
    "            for idx in range(apr_it.begin(level, z, x), apr_it.end()):\n",
    "                y = apr_it.y(idx)\n",
    "\n",
    "                y_start = y * step_size\n",
    "                x_start = x * step_size\n",
    "                z_start = z * step_size\n",
    "\n",
    "                y_end = min(y_start+step_size, py_recon.shape[2])\n",
    "                x_end = min(x_start+step_size, py_recon.shape[1])\n",
    "                z_end = min(z_start+step_size, py_recon.shape[0])\n",
    "\n",
    "                local_labels = labels[z_start:z_end, x_start:x_end, y_start:y_end]\n",
    "\n",
    "                if (local_labels == 0).all(): # case where there is no label\n",
    "                    parts_train[idx] = 0\n",
    "                elif np.sum(local_labels != 0) == 1: # case where there is only one label\n",
    "                    parts_train[idx] = local_labels.max()\n",
    "                else:   # case where there are several labels\n",
    "                    same, l = are_labels_the_same(local_labels)\n",
    "                    if same:\n",
    "                        parts_train[idx] = l\n",
    "                    else:\n",
    "                        parts_train[idx] = 0\n",
    "                        print('Ambiguous label detected, set it to 0.')\n",
    "\n",
    "# pyapr.viewer.parts_viewer(apr, parts_train_C)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def compute_gradients(apr, parts, sobel=True):\n",
    "    par = apr.get_parameters()\n",
    "    dx = pyapr.FloatParticles()\n",
    "    dy = pyapr.FloatParticles()\n",
    "    dz = pyapr.FloatParticles()\n",
    "\n",
    "    pyapr.numerics.gradient(apr, parts, dz, dimension=2, delta=par.dz, sobel=sobel)\n",
    "    pyapr.numerics.gradient(apr, parts, dx, dimension=1, delta=par.dx, sobel=sobel)\n",
    "    pyapr.numerics.gradient(apr, parts, dy, dimension=0, delta=par.dy, sobel=sobel)\n",
    "    return dz, dx, dy\n",
    "\n",
    "\n",
    "def compute_laplacian(apr, parts, sobel=True):\n",
    "    par = apr.get_parameters()\n",
    "    dz, dx, dy = compute_gradients(apr, parts, sobel)\n",
    "    dx2 = pyapr.FloatParticles()\n",
    "    dy2 = pyapr.FloatParticles()\n",
    "    dz2 = pyapr.FloatParticles()\n",
    "    pyapr.numerics.gradient(apr, dz, dz2, dimension=2, delta=par.dz, sobel=sobel)\n",
    "    pyapr.numerics.gradient(apr, dx, dx2, dimension=1, delta=par.dx, sobel=sobel)\n",
    "    pyapr.numerics.gradient(apr, dy, dy2, dimension=0, delta=par.dy, sobel=sobel)\n",
    "    return dz + dx + dy\n",
    "\n",
    "\n",
    "def compute_gradmag(apr, parts, sobel=True):\n",
    "    par = apr.get_parameters()\n",
    "    gradmag = pyapr.FloatParticles()\n",
    "    pyapr.numerics.gradient_magnitude(apr, parts, gradmag, deltas=(par.dz, par.dx, par.dy), sobel=True)\n",
    "    return gradmag\n",
    "\n",
    "\n",
    "def gaussian_blur(apr, parts, sigma=1.5, size=11):\n",
    "    stencil = pyapr.numerics.get_gaussian_stencil(size, sigma, 3, True)\n",
    "    output = pyapr.FloatParticles()\n",
    "    pyapr.numerics.filter.convolve_pencil(apr, parts, output, stencil, use_stencil_downsample=True,\n",
    "                                          normalize_stencil=True, use_reflective_boundary=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "def particle_levels(apr, normalize=True):\n",
    "    lvls = pyapr.ShortParticles(apr.total_number_particles())\n",
    "    lvls.fill_with_levels(apr)\n",
    "    if normalize:\n",
    "        lvls *= (1 / apr.level_max())\n",
    "    return lvls\n",
    "\n",
    "\n",
    "def compute_std(apr, parts, size=5):\n",
    "    dims = apr.org_dims()\n",
    "    box_size = [size if d >= size else 1 for d in dims]\n",
    "    locstd = pyapr.FloatParticles()\n",
    "    pyapr.numerics.local_std(apr, parts, locstd, size=box_size)\n",
    "    return locstd\n",
    "\n",
    "# Compute gradient along a dimension (Sobel filter). dimension can be 0, 1 or 2\n",
    "grad_x, grad_y, grad_z = compute_gradients(apr, parts)\n",
    "\n",
    "# Compute gradient magnitude (central finite differences)\n",
    "grad = compute_gradmag(apr, parts)\n",
    "\n",
    "# Compute local standard deviation around each particle\n",
    "local_std = compute_std(apr, parts, size=5)\n",
    "\n",
    "# Compute lvl for each particle\n",
    "lvl = particle_levels(apr, normalize=True)\n",
    "\n",
    "# Aggregate filters in a feature array\n",
    "f = np.vstack((np.array(parts, copy=True),\n",
    "               lvl,\n",
    "               grad_x,\n",
    "               grad_y,\n",
    "               grad_z,\n",
    "               grad,\n",
    "               local_std)).T\n",
    "\n",
    "f_name = ['Intensity',\n",
    "               'lvl',\n",
    "               'sobel1',\n",
    "               'sobel2',\n",
    "               'sobel3',\n",
    "               'grad',\n",
    "               'local_std']\n",
    "\n",
    "# Fetch data that was manually labelled\n",
    "ind_manual_label = (parts_train != 0)\n",
    "x = f[ind_manual_label, :]\n",
    "y = parts_train[ind_manual_label]-1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/envs/LibAPR/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:174: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/jules/anaconda3/envs/LibAPR/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:191: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# Train classification algorithm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_scaled = scale(x, with_mean=True, with_std=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=.4, random_state=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.6485469e+03 4.9999964e-01 1.3765752e+03 1.1570098e+03 1.2275825e+03\n",
      " 1.3533345e+03 1.2577715e+03]\n",
      "[1.         0.99999714 0.9999999  1.         0.99999994 1.0000005\n",
      " 1.0000007 ]\n"
     ]
    }
   ],
   "source": [
    "print(x.std(axis=0))\n",
    "\n",
    "print(x_scaled.std(axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train SVC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def GridSearch(classifier, tuned_parameters, scoring):\n",
    "    print(\"# Tuning hyper-parameters\")\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(classifier, tuned_parameters, scoring=scoring)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\\n\\n\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\\nGrid scores on development set:\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return clf.best_estimator_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 100, 'kernel': 'linear'}\n",
      "Grid scores on development set:\n",
      "0.852 (+/-0.034) for {'C': 1, 'kernel': 'linear'}\n",
      "0.851 (+/-0.030) for {'C': 10, 'kernel': 'linear'}\n",
      "0.852 (+/-0.028) for {'C': 100, 'kernel': 'linear'}\n",
      "0.851 (+/-0.030) for {'C': 1000, 'kernel': 'linear'}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       597\n",
      "           1       0.84      0.86      0.85       272\n",
      "           2       0.66      0.64      0.65       211\n",
      "\n",
      "    accuracy                           0.83      1080\n",
      "   macro avg       0.80      0.79      0.79      1080\n",
      "weighted avg       0.83      0.83      0.83      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "clf = GridSearch(SVC(), tuned_parameters, scoring='accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'SVM coeffs')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(f_name, clf.coef_.squeeze()[0,:])\n",
    "plt.bar(f_name, clf.coef_.squeeze()[1,:])\n",
    "plt.bar(f_name, clf.coef_.squeeze()[2,:])\n",
    "plt.title('SVM coeffs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 7)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'n_estimators': 100}\n",
      "Grid scores on development set:\n",
      "0.764 (+/-0.019) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 1, 'n_estimators': 10}\n",
      "0.852 (+/-0.018) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 1, 'n_estimators': 100}\n",
      "0.826 (+/-0.015) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}\n",
      "0.862 (+/-0.021) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.846 (+/-0.025) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.871 (+/-0.013) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 100}\n",
      "0.852 (+/-0.022) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}\n",
      "0.872 (+/-0.013) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 100}\n",
      "0.860 (+/-0.018) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5, 'n_estimators': 10}\n",
      "0.870 (+/-0.004) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.847 (+/-0.035) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 1, 'n_estimators': 10}\n",
      "0.858 (+/-0.020) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 1, 'n_estimators': 100}\n",
      "0.849 (+/-0.025) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}\n",
      "0.841 (+/-0.035) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.851 (+/-0.025) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}\n",
      "0.858 (+/-0.010) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 100}\n",
      "0.839 (+/-0.029) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}\n",
      "0.861 (+/-0.023) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 100}\n",
      "0.855 (+/-0.020) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'n_estimators': 10}\n",
      "0.874 (+/-0.008) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'n_estimators': 100}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       597\n",
      "           1       0.90      0.87      0.88       272\n",
      "           2       0.72      0.75      0.74       211\n",
      "\n",
      "    accuracy                           0.87      1080\n",
      "   macro avg       0.85      0.84      0.84      1080\n",
      "weighted avg       0.87      0.87      0.87      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "tuned_parameters = {'loss': ['deviance'],\n",
    "                    'learning_rate': [0.1, 1],\n",
    "                    'n_estimators': [10, 100],\n",
    "                    'max_depth': [1,2,3,4,5]}\n",
    "\n",
    "\n",
    "clf = GridSearch(GradientBoostingClassifier(), tuned_parameters, scoring='accuracy')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random forest (iLastik default)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "\n",
      "{'class_weight': None, 'n_estimators': 500}\n",
      "\n",
      "\n",
      "Grid scores on development set:\n",
      "0.848 (+/-0.039) for {'class_weight': 'balanced', 'n_estimators': 50}\n",
      "0.850 (+/-0.019) for {'class_weight': 'balanced', 'n_estimators': 100}\n",
      "0.851 (+/-0.020) for {'class_weight': 'balanced', 'n_estimators': 500}\n",
      "0.848 (+/-0.029) for {'class_weight': None, 'n_estimators': 50}\n",
      "0.849 (+/-0.034) for {'class_weight': None, 'n_estimators': 100}\n",
      "0.854 (+/-0.020) for {'class_weight': None, 'n_estimators': 500}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       597\n",
      "           1       0.93      0.86      0.89       272\n",
      "           2       0.76      0.77      0.76       211\n",
      "\n",
      "    accuracy                           0.89      1080\n",
      "   macro avg       0.87      0.86      0.86      1080\n",
      "weighted avg       0.89      0.89      0.89      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tuned_parameters = {'class_weight': ['balanced', None],\n",
    "                    'n_estimators': [50, 100, 500]}\n",
    "\n",
    "clf = GridSearch(RandomForestClassifier(), tuned_parameters, scoring='f1_macro')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "def display_segmentation(u, lmap, vdim=2):\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer(ndisplay=vdim)\n",
    "        # add the volume\n",
    "        viewer.add_image(u, name='Intensity image')\n",
    "        # add labels\n",
    "        viewer.add_labels(lmap, name='segmentation')\n",
    "\n",
    "def predict_and_display(apr, parts, clf, x):\n",
    "    data = np.array(pyapr.numerics.reconstruction.recon_pc(apr, parts), copy=False)\n",
    "    y_pred = clf.predict(x)\n",
    "    mask = np.array(parts, copy=False)\n",
    "    for i, elem in enumerate(y_pred):\n",
    "        mask[i] = elem\n",
    "    labels = np.array(pyapr.numerics.reconstruction.recon_pc(apr, parts), copy=False)\n",
    "    display_segmentation(data, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/envs/LibAPR/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:174: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/jules/anaconda3/envs/LibAPR/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:191: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "pyapr.io.read(fpath_apr, apr, parts)\n",
    "predict_and_display(apr, parts, clf, scale(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2849f61f",
   "language": "python",
   "display_name": "PyCharm (PyLibAPR)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}