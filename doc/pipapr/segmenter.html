<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pipapr.segmenter API documentation</title>
<meta name="description" content="Module containing classes and functions relative to Segmentation …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pipapr.segmenter</code></h1>
</header>
<section id="section-intro">
<p>Module containing classes and functions relative to Segmentation.</p>
<p>By using this code you agree to the terms of the software license agreement.</p>
<p>© Copyright 2020 Wyss Center for Bio and Neuro Engineering – All rights reserved</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Module containing classes and functions relative to Segmentation.

By using this code you agree to the terms of the software license agreement.

© Copyright 2020 Wyss Center for Bio and Neuro Engineering – All rights reserved
&#34;&#34;&#34;

import pandas as pd
import pipapr
import numpy as np
import pyapr
from joblib import load
from time import time
import cv2 as cv
import sparse
import napari
from tqdm import tqdm
import os
from time import sleep

def _predict_on_APR_block(x, clf, n_parts=1e7, output=&#39;class&#39;, verbose=False):
    &#34;&#34;&#34;
    Predict particle class with the trained classifier clf on the precomputed features f using a
    blocked strategy to avoid memory segfault.

    Parameters
    ----------
    x: (np.array) features (n_particle, n_features) for particle prediction
    n_parts: (int) number of particles in the batch to predict
    output: (str) output type, can be &#39;class&#39; where each particle get assigned a class or &#39;proba&#39; where each
                particle get assigned a probability of belonging to each class.
    verbose: (bool) control function verbosity

    Returns
    -------
    Class prediction for each particle.
    &#34;&#34;&#34;

    # Predict on numpy array by block to avoid memory issues
    if verbose:
        t = time()

    n_block = int(np.ceil(x.shape[0] / n_parts))
    if int(n_parts) != n_parts:
        raise ValueError(&#39;Error: n_parts must be an int.&#39;)
    n_parts = int(n_parts)
    clf[1].set_params(n_jobs=-1)

    if output == &#39;class&#39;:
        y_pred = np.empty((x.shape[0]))
        for i in tqdm(range(n_block), desc=&#39;Predicting particle type&#39;):
            y_pred[i * n_parts:min((i + 1) * n_parts, x.shape[0])] = clf.predict(
                x[i * n_parts:min((i + 1) * n_parts, x.shape[0])])
        # Transform numpy array to ParticleData
        parts_pred = pyapr.ShortParticles(y_pred.astype(&#39;uint16&#39;))

    elif output == &#39;proba&#39;:
        y_pred = np.empty((x.shape[0], len(clf.classes_)))
        for i in tqdm(range(n_block), desc=&#39;Predicting particle type&#39;):
            y_pred[i * n_parts:min((i + 1) * n_parts, x.shape[0]), :] = clf.predict_proba(
                x[i * n_parts:min((i + 1) * n_parts, x.shape[0])])
        # Transform numpy array to ParticleData
        parts_pred = []
        for i in range(len(clf.classes_)):
            parts_pred.append(pyapr.ShortParticles(
                                                   (y_pred[:, i]*(2**16-1))
                                                    .astype(&#39;uint16&#39;)))
    else:
        raise ValueError(&#39;Unknown output \&#39;{}\&#39; for APR block prediction.&#39;.format(output))

    if verbose:
        print(&#39;Blocked prediction took {:0.3f} s.\n&#39;.format(time() - t))


    return parts_pred


def map_feature(data, hash_idx, features):
    &#34;&#34;&#34;
    Map feature values to segmented particle data.

    Parameters
    ----------
    data: (ParticleData) connected component particle array
    hash_idx: (array) array containing the number of each connected component in ascendant order
    features: (array) array containing the values to map

    Returns
    -------
    Array of mapped values
    &#34;&#34;&#34;

    if len(hash_idx) != len(features):
        raise ValueError(&#39;Error: hash_idx and features must have the same length.&#39;)

    # Create hash dict
    hash_dict = {x: y for x, y in zip(hash_idx, features)}
    # Replace 0 by 0
    hash_dict[0] = 0

    mp = np.arange(0, data.max() + 1)
    mp[list(hash_dict.keys())] = list(hash_dict.values())
    return mp[np.array(data, copy=False)]


class tileSegmenter():
    &#34;&#34;&#34;
    Class used to segment tiles. It is instantiated with a tileLoader object, a previously trained classifier,
    a function to compute features (the same features used to train the classifier and a function to get the
    post processed connected component for the classifier output.

    &#34;&#34;&#34;

    def __init__(self, clf, func_to_compute_features, func_to_get_cc, verbose):
        &#34;&#34;&#34;

        Parameters
        ----------
        tile: (tileLoader) tile object for loading the tile (or containing the preloaded tile).
        path_classifier: (str) path to pre-trained classifier
        func_to_compute_features: (func) function to compute the features on ParticleData. Must be the same set of
                                        as the one used to train the classifier.
        func_to_get_cc: (func) function to post process the segmentation map into a connected component (each cell has
                                        a unique id)
        &#34;&#34;&#34;

        # Store classifier
        self.clf = clf
        # Store function to compute features
        self.func_to_compute_features = func_to_compute_features
        # Store post processing steps
        self.func_to_get_cc = func_to_get_cc
        # Verbose
        self.verbose = verbose

    @classmethod
    def from_trainer(cls,
                     trainer,
                     verbose=True):
        &#34;&#34;&#34;
        Instantiate tileSegmenter object with a tileTrainer object.

        Parameters
        ----------
        trainer: (pipapr.segmenter.tileTrainer) trainer object previously trained for segmentation
        verbose: (bool) control function output

        Returns
        -------
        tileSegmenter object
        &#34;&#34;&#34;

        return cls(clf=trainer.clf,
                   func_to_compute_features=trainer.func_to_compute_features,
                   func_to_get_cc=trainer.func_to_get_cc,
                   verbose=verbose)

    @classmethod
    def from_classifier(cls,
                        classifier,
                        func_to_compute_features,
                        func_to_get_cc=None,
                        verbose=True):
        &#34;&#34;&#34;
        Instantiate tileSegmenter object with a classifier, function to compute the features and to get the
        connected components.

        Parameters
        ----------
        classifier
        func_to_compute_features: (func) function to compute features used by the classifier to perform
                                    the segmentation.
        func_to_get_cc: (func) function to compute the connected component from the classifier prediction.
        verbose: (bool) control function output.

        Returns
        -------
        tileSegmenter object
        &#34;&#34;&#34;

        if isinstance(classifier, str):
            clf = load(classifier)
        else:
            clf = classifier

        return cls(clf=clf,
                   func_to_compute_features=func_to_compute_features,
                   func_to_get_cc=func_to_get_cc,
                   verbose=verbose)

    def compute_segmentation(self, tile: pipapr.loader.tileLoader,
                             save_cc=True, save_mask=False):
        &#34;&#34;&#34;
        Compute the segmentation and stores the result as an independent APR.

        Parameters
        ----------
        verbose: (bool) control the verbosity of the function to print some info

        Returns
        -------
        None
        &#34;&#34;&#34;

        if tile.apr is None:
            tile.load_tile()

        # Compute features on APR
        if self.verbose:
            t = time()
            print(&#39;Computing features on APR&#39;)
        f = self.func_to_compute_features(tile.apr, tile.parts)
        self.filtered_APR = f
        if self.verbose:
            print(&#39;Features computation took {:0.2f} s.&#39;.format(time()-t))

        # Predict particle class
        parts_pred = _predict_on_APR_block(f, self.clf, verbose=self.verbose)
        if self.verbose:
            # Display inference info
            print(&#39;\n****** INFERENCE RESULTS ******&#39;)
            for l in self.clf.classes_:
                print(&#39;Class {}: {} particles ({:0.2f}%)&#39;.format(l, np.sum(parts_pred == l),
                                                      np.sum(parts_pred == l) / len(parts_pred) * 100))
            print(&#39;*******************************&#39;)

        # Compute connected component from classification
        if self.func_to_get_cc is not None:
            cc = self.func_to_get_cc(tile.apr, parts_pred)
            tile.parts_cc = cc

        # Save results
        if save_mask:
            self._save_segmentation(tile.path, name=&#39;segmentation mask&#39;, parts=parts_pred)
        if save_cc:
            self._save_segmentation(tile.path, name=&#39;segmentation cc&#39;, parts=cc)

        tile.parts_mask = parts_pred

    def _save_segmentation(self, path, name, parts):
        &#34;&#34;&#34;
        Save segmentation particles by appending the original APR file.

        Parameters
        ----------
        parts: (pyapr.ParticleData) particles to save. Note that the APR tree should be the same otherwise the data
                                    will be inconsistent and not readable.

        Returns
        -------
        None
        &#34;&#34;&#34;
        aprfile = pyapr.io.APRFile()
        aprfile.set_read_write_tree(True)
        aprfile.open(path, &#39;READWRITE&#39;)
        aprfile.write_particles(name, parts, t=0)
        aprfile.close()


class tileCells():
    &#34;&#34;&#34;
    Class for storing the high level cell information (e.g. cell center position).
    It allows to extract cells position and merge them across multiple tiles taking into account the precomputed
    registration.
    &#34;&#34;&#34;

    def __init__(self,
                 tiles: pipapr.parser.tileParser,
                 database: (str, pd.DataFrame),
                 verbose=True):
        &#34;&#34;&#34;

        Parameters
        ----------
        tiles: (tileLoader) tile object for loading the tile (or containing the preloaded tile).
        database (pd.DataFrame, str) dataframe (or path to the csv file) containing the registration parameters
                        to correctly place each tile.

        &#34;&#34;&#34;

        # If database is a path then load database, if it&#39;s a DataFrame keep it as it is.
        if isinstance(database, str):
            self.database = pd.read_csv(database)
        elif isinstance(database, pd.DataFrame):
            self.database = database
        else:
            raise TypeError(&#39;Error: database of wrong type.&#39;)

        self.tiles = tiles
        self.path = tiles.path
        self.type = tiles.type
        self.tiles_list = tiles.tiles_list
        self.n_tiles = tiles.n_tiles
        self.ncol = tiles.ncol
        self.nrow = tiles.nrow
        self.neighbors = tiles.neighbors
        self.n_edges = tiles.n_edges
        self.path_list = tiles.path_list
        self.frame_size = tiles.frame_size
        self.verbose = verbose

        self.cells = None
        self.atlas = None

    def extract_and_merge_cells(self, lowe_ratio=0.7, distance_max=5):
        &#34;&#34;&#34;
        Function to extract cell positions in each tile and merging across all tiles.
        Identical cells on overlapping area are automatically detected using Flann method.

        Parameters
        ----------
        lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                            above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                            a second detection on the neighboring tile.
        distance_max: (float) maximum distance in pixel for two cells to be considered the same.

        Returns
        -------
        None
        &#34;&#34;&#34;
        
        for tile in tqdm(self.tiles, desc=&#39;Extracting and merging cells..&#39;):
            tile.load_tile()
            tile.load_segmentation()
            
            # Remove objects on the edge
            tile = self._remove_edge_cells(tile)

            # Initialized merged cells for the first tile
            if self.cells is None:
                self.cells = pyapr.numerics.transform.find_label_centers(tile.apr, tile.parts_cc, tile.parts)
                self.cells += self._get_tile_position(tile.row, tile.col)
            # Then merge the rest on the first tile
            else:
                self._merge_cells(tile, lowe_ratio=lowe_ratio, distance_max=distance_max)

    def save_cells(self, output_path):
        &#34;&#34;&#34;
        Save cells as a CSV file.

        Parameters
        ----------
        output_path: (str) path for saving the CSV file.

        Returns
        -------
        None
        &#34;&#34;&#34;

        pd.DataFrame(self.cells).to_csv(output_path, header=[&#39;z&#39;, &#39;y&#39;, &#39;x&#39;])
        
    def _remove_edge_cells(self, tile):
        &#34;&#34;&#34;
        Remove cells/objects that are touching the tile edge and if this edge is overlapping another tile.

        Parameters
        ----------
        tile: (tileLoader) tile to remove the object on
        verbose: option to display information

        Returns
        -------
        tileLoader with removed objects.
        &#34;&#34;&#34;

        shape = tile.apr.shape()
        s_min = np.array([np.nan, 0, 0])
        s_max = np.array([np.nan, shape[1], shape[2]])
        
        minc, maxc = pyapr.numerics.transform.find_objects(tile.apr, tile.parts_cc)

        for i in range(1, minc.shape[0]):
            if (minc[i, :] == s_min).any():
                ind = np.where(tile.parts_cc == i)
                for ii in ind[0]:
                    tile.parts_cc[ii] = 0
            if (maxc[i, :] == s_max).any():
                ind = np.where(tile.parts_cc == i)
                for ii in ind[0]:
                    tile.parts_cc[ii] = 0

        return tile

    def _merge_cells(self, tile, lowe_ratio, distance_max):
        &#34;&#34;&#34;
        Function to merge cells on a tile to the final cells list and remove duplicate.

        Parameters
        ----------
        tile: (tileLoader) tile from which to merge cells
        lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                            above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                            a second detection on the neighboring tile.
        distance_max: (float) maximum distance in pixel for two cells to be considered the same.

        Returns
        -------
        None
        &#34;&#34;&#34;

        r1 = np.max(self.cells, axis=0)
        r2 = self._get_tile_position(tile.row, tile.col)

        v_size = np.array(tile.apr.shape())

        # Define the overlapping area
        overlap_i = r2
        overlap_f = np.min((r1 + v_size, r2 + v_size), axis=0)

        # Retrieve cell centers
        cells2 = pyapr.numerics.transform.find_label_centers(tile.apr, tile.parts_cc, tile.parts)
        cells2 += r2

        # Filter cells to keep only those on the overlapping area
        for i in range(3):
            if i == 0:
                ind = np.where(self.cells[:, i] &lt; overlap_i[i])[0]
            else:
                ind = np.concatenate((ind, np.where(self.cells[:, i] &lt; overlap_i[i])[0]))
            ind = np.concatenate((ind, np.where(self.cells[:, i] &gt; overlap_f[i])[0]))
        ind = np.unique(ind)

        cells1_out = self.cells[ind, :]
        cells1_overlap = np.delete(self.cells, ind, axis=0)

        for i in range(3):
            if i == 0:
                ind = np.where(cells2[:, i] &lt; overlap_i[i])[0]
            else:
                ind = np.concatenate((ind, np.where(cells2[:, i] &lt; overlap_i[i])[0]))
            ind = np.concatenate((ind, np.where(cells2[:, i] &gt; overlap_f[i])[0]))
        ind = np.unique(ind)

        cells2_out = cells2[ind, :]
        cells2_overlap = np.delete(cells2, ind, axis=0)

        cells_filtered_overlap = self._filter_cells_flann(cells1_overlap,
                                                          cells2_overlap,
                                                          lowe_ratio=lowe_ratio,
                                                          distance_max=distance_max)

        self.cells = np.vstack((cells1_out, cells2_out, cells_filtered_overlap))

    def _get_tile_position(self, row, col):
        &#34;&#34;&#34;
        Function to get the absolute tile position defined by it&#39;s coordinate in the multitile set.

        Parameters
        ----------
        row: (int) row number
        col: (int) column number

        Returns
        -------
        (np.array) tile absolute position
        &#34;&#34;&#34;

        df = self.database
        tile_df = df[(df[&#39;row&#39;] == row) &amp; (df[&#39;col&#39;] == col)]
        px = tile_df[&#39;ABS_H&#39;].values[0]
        py = tile_df[&#39;ABS_V&#39;].values[0]
        pz = tile_df[&#39;ABS_D&#39;].values[0]

        return np.array([pz, py, px])

    def _filter_cells_flann(self, c1, c2, lowe_ratio=0.7, distance_max=5):
        &#34;&#34;&#34;
        Remove cells duplicate using Flann criteria and distance threshold.

        Parameters
        ----------
        c1: (np.array) array containing the first set cells coordinates
        c2: (np.array) array containing the second set cells coordinates
        lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                            above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                            a second detection on the neighboring tile.
        distance_max: (float) maximum distance in pixel for two cells to be considered the same.
        verbose: (bool) control function verbosity

        Returns
        -------
        (np.array) array containing the merged sets without the duplicates.
        &#34;&#34;&#34;

        if lowe_ratio &lt; 0 or lowe_ratio &gt; 1:
            raise ValueError(&#39;Lowe ratio is {}, expected between 0 and 1.&#39;.format(lowe_ratio))

        # Match cells descriptors by using Flann method
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=4)
        search_params = dict(checks=100)
        flann = cv.FlannBasedMatcher(index_params, search_params)
        matches = flann.knnMatch(np.float32(c1), np.float32(c2), k=2)
        # store all the good matches as per Lowe&#39;s ratio test.
        good = []
        for m, n in matches:
            if m.distance &lt; lowe_ratio*n.distance and m.distance &lt; distance_max:
                good.append(m)

        # Remove cells that are present in both volumes
        ind_c1 = [m.queryIdx for m in good]
        ind_c2 = [m.trainIdx for m in good]

        # For now I just remove the cells in c2 but merging strategies can be better
        c2 = np.delete(c2, ind_c2, axis=0)

        # Display info
        if self.verbose:
            print(&#39;{:0.2f}% of cells were removed.&#39;.format(len(ind_c2)/(c1.shape[0]+c2.shape[0]-len(ind_c2))*100))

        return np.vstack((c1, c2))


class tileTrainer():
    &#34;&#34;&#34;
    Class used to train a classifier that works directly on APR data. It uses Napari to manually add labels.

    &#34;&#34;&#34;

    def __init__(self,
                 tile: pipapr.loader.tileLoader,
                 func_to_compute_features,
                 func_to_get_cc=None):

        tile.load_tile()
        self.tile = tile
        self.apr = tile.apr
        self.parts = tile.parts
        self.apr_it = self.apr.iterator()
        self.shape = tile.apr.shape()
        self.func_to_compute_features = func_to_compute_features
        self.func_to_get_cc = func_to_get_cc

        self.labels_manual = None
        self.pixel_list = None
        self.labels = None
        self.use_sparse_labels = None
        self.parts_train_idx = None
        self.clf = None
        self.parts_mask = None
        self.parts_cc = None
        self.f = None

    def manually_annotate(self, use_sparse_labels=True, **kwargs):
        &#34;&#34;&#34;
        Manually annotate dataset using Napari.

        Parameters
        ----------
        use_sparse_labels: (bool) use sparse array to store the labels (memory efficient but slower graphics)

        Returns
        -------
        None
        &#34;&#34;&#34;
        self.sparse = use_sparse_labels

        if self.sparse:
            # We create a sparse array that supports inserting data (COO does not)
            self.labels_manual = sparse.DOK(shape=self.shape, dtype=&#39;uint8&#39;)
        else:
            self.labels_manual = np.empty(self.shape, dtype=&#39;uint8&#39;)

        # We call napari with the APRSlicer and the sparse array for storing the manual annotations
        viewer = napari.Viewer()
        image_layer = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts), **kwargs)
        viewer.add_layer(image_layer)
        viewer.add_labels(self.labels_manual)
        viewer.show(block=True)

        # We extract labels and pixel coordinate from the sparse array
        if self.sparse:
            self.labels_manual = self.labels_manual.to_coo()
        else:
            self.labels_manual = sparse.COO.from_numpy(self.labels_manual)

        self.pixel_list = self.labels_manual.coords.T
        self.labels = self.labels_manual.data

    def add_annotations(self, use_sparse_labels=True, **kwargs):
        &#34;&#34;&#34;
        Add annotations on previously annotated dataset.

        Parameters
        ----------
        use_sparse_labels: (bool) use sparse array to store the labels (memory efficient but slower graphics)

        Returns
        -------
        None
        &#34;&#34;&#34;

        self.sparse = use_sparse_labels

        if self.sparse:
            # We create a sparse array that supports inserting data (COO does not)
            self.labels_manual = sparse.DOK(self.labels_manual)
        else:
            self.labels_manual = self.labels_manual.todense()

        # We call napari with the APRSlicer and the sparse array for storing the manual annotations
        viewer = napari.Viewer()
        image_layer = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts), **kwargs)
        viewer.add_layer(image_layer)
        viewer.add_labels(self.labels_manual)
        viewer.show(block=True)

        # We extract labels and pixel coordinate from the sparse array
        if self.sparse:
            self.labels_manual = self.labels_manual.to_coo()
        else:
            self.labels_manual = sparse.COO.from_numpy(self.labels_manual)

        self.pixel_list = self.labels_manual.coords.T
        self.labels = self.labels_manual.data

    def save_labels(self, path=None):
        &#34;&#34;&#34;
        Save labels as numpy array with columns corresponding to [z, y, x, label].

        Parameters
        ----------
        path: (str) path to save labels. By default it saves them in the data root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;

        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;manual_labels.npy&#39;)

        to_be_saved = np.hstack((self.pixel_list, self.labels[:, np.newaxis]))
        np.save(path, to_be_saved)

    def load_labels(self, path=None):
        &#34;&#34;&#34;
        Load previously saved labels as numpy array with columns corresponding to [z, y, x, label].

        Parameters
        ----------
        path: (str) path to load the saved labels. By default it loads them in the data root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;
        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;manual_labels.npy&#39;)

        data = np.load(path)
        self.pixel_list = data[:, :-1]
        self.labels = data[:, -1]
        self.labels_manual = sparse.COO(coords=self.pixel_list.T, data=self.labels)

    def train_classifier(self, verbose=True):
        &#34;&#34;&#34;
        Train the classifier for segmentation.

        Parameters
        ----------
        verbose: (bool) option to print out information.

        Returns
        -------
        None
        &#34;&#34;&#34;
        if self.pixel_list is None:
            raise ValueError(&#39;Error: annotate dataset or load annotations before training classifier.&#39;)

        from sklearn import preprocessing
        from sklearn.pipeline import make_pipeline
        from sklearn.ensemble import RandomForestClassifier

        # We sample pixel_list on APR grid
        self._sample_pixel_list_on_APR()

        # We remove ambiguous case where a particle was labeled differently
        self._remove_ambiguities(verbose=verbose)

        # We compute features and train the classifier
        if self.f is None:
            f = self.func_to_compute_features(self.apr, self.parts)

        # Fetch data that was manually labelled
        x = f[self.parts_train_idx]
        y = self.parts_labels

        # Train random forest
        clf = make_pipeline(preprocessing.StandardScaler(with_mean=True, with_std=True),
                            RandomForestClassifier(n_estimators=10, class_weight=&#39;balanced&#39;))
        t = time()
        clf.fit(x, y.ravel())
        print(&#39;Training took {} s.\n&#39;.format(time() - t))

        x_pred = clf.predict(x)

        # Display training info
        if verbose:
            print(&#39;\n****** TRAINING RESULTS ******&#39;)
            print(&#39;Total accuracy: {:0.2f}%&#39;.format(np.sum(x_pred == y) / y.size * 100))
            for l in self.unique_labels:
                print(&#39;Class {} accuracy: {:0.2f}% ({} cell particles)&#39;.format(l,
                    np.sum((x_pred == y) * (y == l)) / np.sum(y == l) * 100, np.sum(y == l)))
            print(&#39;******************************\n&#39;)

        self.clf = clf
        self.f = f

    def segment_training_tile(self, bg_label=None, display_result=True, verbose=True):
        &#34;&#34;&#34;
        Apply classifier to the whole tile and display segmentation results using Napari.

        Parameters
        ----------
        display_result: (bool) option to display segmentation results using Napari
        verbose: (bool) option to print out information.

        Returns
        -------
        None
        &#34;&#34;&#34;

        # Apply on whole dataset
        if self.parts_mask is None:
            parts_pred = _predict_on_APR_block(self.f, self.clf, verbose=verbose)
            self.parts_mask = parts_pred

        if (self.func_to_get_cc is not None) and self.parts_cc is None:
            self.parts_cc = self.func_to_get_cc(self.apr, self.parts_mask.copy())

        # Display inference info
        if verbose:
            print(&#39;\n****** INFERENCE RESULTS ******&#39;)
            for l in self.unique_labels:
                print(&#39;Class {}: {} cell particles ({:0.2f}%)&#39;.format(l, np.sum(self.parts_mask == l),
                                                            np.sum(self.parts_mask == l) / len(self.parts_mask) * 100))
            print(&#39;******************************\n&#39;)

        # Display segmentation using Napari
        if display_result:
            if self.parts_cc is not None:
                pipapr.viewer.display_segmentation(self.apr, self.parts, self.parts_cc)
            elif bg_label is not None:
                parts_pred = np.array(self.parts_mask.copy())
                parts_pred[parts_pred == bg_label] = 0
                parts_pred = pyapr.ShortParticles(parts_pred)
                pipapr.viewer.display_segmentation(self.apr, self.parts, parts_pred)

    def display_training_annotations(self, **kwargs):
        &#34;&#34;&#34;
        Display manual annotations and their sampling on APR grid (if available).

        Returns
        -------
        None
        &#34;&#34;&#34;
        image_nap = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts),
                                        opacity=0.7, **kwargs)
        viewer = napari.Viewer()
        viewer.add_layer(image_nap)
        viewer.add_labels(self.labels_manual, name=&#39;Manual labels&#39;, opacity=0.5)
        if self.parts_labels is not None:
            mask = np.zeros_like(self.parts, dtype=&#39;uint16&#39;)
            mask[self.parts_train_idx] = self.parts_labels
            label_nap = napari.layers.Labels(data=pyapr.data_containers.APRSlicer(self.apr, pyapr.ShortParticles(mask)),
                                             name=&#39;APR labels&#39;, opacity=0.5)
            viewer.add_layer(label_nap)
        napari.run()

    def apply_on_tile(self, tile, bg_label=None, func_to_get_cc=None, display_result=True, verbose=True):
        &#34;&#34;&#34;
        Apply classifier to the whole tile and display segmentation results using Napari.

        Parameters
        ----------
        display_result: (bool) option to display segmentation results using Napari
        verbose: (bool) option to print out information.

        Returns
        -------
        None
        &#34;&#34;&#34;

        # Apply on whole dataset
        if tile.apr is None:
            tile.load_tile()
        f = self.func_to_compute_features(tile.apr, tile.parts)
        parts_pred = _predict_on_APR_block(f, self.clf, verbose=verbose)
        tile.parts_mask = parts_pred.copy()

        # Display inference info
        if verbose:
            print(&#39;\n****** INFERENCE RESULTS ******&#39;)
            for l in self.unique_labels:
                print(&#39;Class {}: {} cell particles ({:0.2f}%)&#39;.format(l, np.sum(parts_pred == l),
                                                            np.sum(parts_pred == l) / len(parts_pred) * 100))
            print(&#39;******************************\n&#39;)

        # Display segmentation using Napari
        if display_result:
            if func_to_get_cc is not None:
                tile.parts_cc = func_to_get_cc(tile.apr, parts_pred)
                pipapr.viewer.display_segmentation(self.apr, self.parts, tile.parts_cc)
            elif bg_label is not None:
                parts_pred = np.array(parts_pred)
                parts_pred[parts_pred==bg_label] = 0
                parts_pred = pyapr.ShortParticles(parts_pred)
                pipapr.viewer.display_segmentation(self.apr, self.parts, parts_pred)

    def save_classifier(self, path=None):
        &#34;&#34;&#34;
        Save the trained classifier.

        Parameters
        ----------
        path: (str) path for saving the classifier. By default, it is saved in the data root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;
        from joblib import dump

        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;random_forest_n100.joblib&#39;)

        dump(self.clf, path)

    def load_classifier(self, path=None):
        &#34;&#34;&#34;
        Load a trained classifier.

        Parameters
        ----------
        path: (str) path for loading the classifier. By default, it is loaded from root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;
        from joblib import load

        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;random_forest_n100.joblib&#39;)

        self.clf = load(path)

    def display_features(self):
        &#34;&#34;&#34;
        Display the computed features.

        &#34;&#34;&#34;
        if self.f is None:
            raise TypeError(&#39;Error: filters can&#39;&#39;t be displayed because they were not computed&#39;)

        viewer = napari.Viewer()
        for i in range(f.shape[1]):
            viewer.add_layer(pipapr.viewer.apr_to_napari_Image(self.apr, pyapr.FloatParticles(f[:, i])))
        napari.run()

    def _remove_ambiguities(self, verbose):
        &#34;&#34;&#34;
        Remove particles that have been labelled with different labels.

        Parameters
        ----------
        verbose: (bool) option to print out information.

        Returns
        -------

        &#34;&#34;&#34;
        if self.parts_train_idx is None:
            raise ValueError(&#39;Error: train classifier before removing ambiguities.&#39;)

        idx_unique = np.unique(self.parts_train_idx)

        parts_train = []
        parts_labels = []

        cnt = 0
        for idx in idx_unique:
            local_labels = self.labels[self.parts_train_idx==idx]
            is_same, l = self._are_labels_the_same(local_labels)
            if is_same:
                # If labels are the same we assign it
                parts_labels.append(l)
                parts_train.append(idx)
            else:
                cnt += 1

        self.parts_train_idx = np.array(parts_train)
        self.parts_labels = np.array(parts_labels)
        self.unique_labels = np.unique(self.parts_labels)

        if verbose:
            print(&#39;\n********* ANNOTATIONS ***********&#39;)
            print(&#39;{} ambiguous particles were removed.&#39;.format(cnt))
            print(&#39;{} particles were labeled.&#39;.format(self.parts_labels.shape[0]))
            for l in self.unique_labels:
                print(&#39;{} particles ({:0.2f}%) were labeled as {}.&#39;.format(np.sum(self.parts_labels==l),
                                                                       100*np.sum(self.parts_labels==l)/self.parts_labels.shape[0],
                                                                        l))
            print(&#39;***********************************\n&#39;)

    def _sample_pixel_list_on_APR(self):
        &#34;&#34;&#34;
        Convert manual annotations coordinates from pixel to APR.

        Returns
        -------
        None
        &#34;&#34;&#34;
        self.parts_train_idx = np.empty(self.pixel_list.shape[0], dtype=&#39;uint64&#39;)

        for i in tqdm(range(self.pixel_list.shape[0]), desc=&#39;Sampling labels on APR.&#39;):
            idx = self._find_particle(self.pixel_list[i, :])

            self.parts_train_idx[i] = idx

    def _find_particle(self, coords):
        &#34;&#34;&#34;
        Find particle index corresponding to pixel location coords.

        Parameters
        ----------
        coords: (array) pixel coordinate [z, y, x]

        Returns
        -------
        idx: (int) particle index
        &#34;&#34;&#34;
        # TODO: @JOEL PUT THIS IN C++ PLEASE
        for level in range(self.apr_it.level_min(), self.apr_it.level_max()+1):
            particle_size = 2 ** (self.apr.level_max() - level)
            z_l, x_l, y_l = coords // particle_size
            for idx in range(self.apr_it.begin(level, z_l, x_l), self.apr_it.end()):
                if self.apr_it.y(idx) == y_l:
                    # if np.sqrt(np.sum((coords-np.array([z_l, x_l, y_l])*particle_size)**2))/particle_size &gt; np.sqrt(3):
                    #     print(&#39;ich&#39;)
                    return idx

    def _order_labels(self):
        &#34;&#34;&#34;
        Order pixel_list in z incresing order, then y increasing order and finally x increasing order.

        Returns
        -------
        None
        &#34;&#34;&#34;
        for d in range(3, 0):
            ind = np.argsort(self.pixel_list[:, d])
            self.pixel_list = self.pixel_list[ind]
            self.labels = self.labels[ind]

    @staticmethod
    def _are_labels_the_same(local_labels):
        &#34;&#34;&#34;
        Determine if manual labels in particle are the same and return the labels

        Parameters
        ----------
        local_labels: (array) particle labels

        Returns
        -------
        ((bool): True if labels are the same, (int) corresponding label)
        &#34;&#34;&#34;
        return ((local_labels == local_labels[0]).all(), local_labels[0])</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pipapr.segmenter.map_feature"><code class="name flex">
<span>def <span class="ident">map_feature</span></span>(<span>data, hash_idx, features)</span>
</code></dt>
<dd>
<div class="desc"><p>Map feature values to segmented particle data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>(ParticleData) connected component particle array</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>hash_idx</code></strong> :&ensp;<code>(array) array containing the number</code> of <code>each connected component in ascendant order</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>features</code></strong> :&ensp;<code>(array) array containing the values to map</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Array</code> of <code>mapped values</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_feature(data, hash_idx, features):
    &#34;&#34;&#34;
    Map feature values to segmented particle data.

    Parameters
    ----------
    data: (ParticleData) connected component particle array
    hash_idx: (array) array containing the number of each connected component in ascendant order
    features: (array) array containing the values to map

    Returns
    -------
    Array of mapped values
    &#34;&#34;&#34;

    if len(hash_idx) != len(features):
        raise ValueError(&#39;Error: hash_idx and features must have the same length.&#39;)

    # Create hash dict
    hash_dict = {x: y for x, y in zip(hash_idx, features)}
    # Replace 0 by 0
    hash_dict[0] = 0

    mp = np.arange(0, data.max() + 1)
    mp[list(hash_dict.keys())] = list(hash_dict.values())
    return mp[np.array(data, copy=False)]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pipapr.segmenter.tileCells"><code class="flex name class">
<span>class <span class="ident">tileCells</span></span>
<span>(</span><span>tiles: <a title="pipapr.parser.tileParser" href="parser.html#pipapr.parser.tileParser">tileParser</a>, database: (<class 'str'>, <class 'pandas.core.frame.DataFrame'>), verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for storing the high level cell information (e.g. cell center position).
It allows to extract cells position and merge them across multiple tiles taking into account the precomputed
registration.</p>
<h2 id="parameters">Parameters</h2>
<p>tiles: (tileLoader) tile object for loading the tile (or containing the preloaded tile).
database (pd.DataFrame, str) dataframe (or path to the csv file) containing the registration parameters
to correctly place each tile.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class tileCells():
    &#34;&#34;&#34;
    Class for storing the high level cell information (e.g. cell center position).
    It allows to extract cells position and merge them across multiple tiles taking into account the precomputed
    registration.
    &#34;&#34;&#34;

    def __init__(self,
                 tiles: pipapr.parser.tileParser,
                 database: (str, pd.DataFrame),
                 verbose=True):
        &#34;&#34;&#34;

        Parameters
        ----------
        tiles: (tileLoader) tile object for loading the tile (or containing the preloaded tile).
        database (pd.DataFrame, str) dataframe (or path to the csv file) containing the registration parameters
                        to correctly place each tile.

        &#34;&#34;&#34;

        # If database is a path then load database, if it&#39;s a DataFrame keep it as it is.
        if isinstance(database, str):
            self.database = pd.read_csv(database)
        elif isinstance(database, pd.DataFrame):
            self.database = database
        else:
            raise TypeError(&#39;Error: database of wrong type.&#39;)

        self.tiles = tiles
        self.path = tiles.path
        self.type = tiles.type
        self.tiles_list = tiles.tiles_list
        self.n_tiles = tiles.n_tiles
        self.ncol = tiles.ncol
        self.nrow = tiles.nrow
        self.neighbors = tiles.neighbors
        self.n_edges = tiles.n_edges
        self.path_list = tiles.path_list
        self.frame_size = tiles.frame_size
        self.verbose = verbose

        self.cells = None
        self.atlas = None

    def extract_and_merge_cells(self, lowe_ratio=0.7, distance_max=5):
        &#34;&#34;&#34;
        Function to extract cell positions in each tile and merging across all tiles.
        Identical cells on overlapping area are automatically detected using Flann method.

        Parameters
        ----------
        lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                            above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                            a second detection on the neighboring tile.
        distance_max: (float) maximum distance in pixel for two cells to be considered the same.

        Returns
        -------
        None
        &#34;&#34;&#34;
        
        for tile in tqdm(self.tiles, desc=&#39;Extracting and merging cells..&#39;):
            tile.load_tile()
            tile.load_segmentation()
            
            # Remove objects on the edge
            tile = self._remove_edge_cells(tile)

            # Initialized merged cells for the first tile
            if self.cells is None:
                self.cells = pyapr.numerics.transform.find_label_centers(tile.apr, tile.parts_cc, tile.parts)
                self.cells += self._get_tile_position(tile.row, tile.col)
            # Then merge the rest on the first tile
            else:
                self._merge_cells(tile, lowe_ratio=lowe_ratio, distance_max=distance_max)

    def save_cells(self, output_path):
        &#34;&#34;&#34;
        Save cells as a CSV file.

        Parameters
        ----------
        output_path: (str) path for saving the CSV file.

        Returns
        -------
        None
        &#34;&#34;&#34;

        pd.DataFrame(self.cells).to_csv(output_path, header=[&#39;z&#39;, &#39;y&#39;, &#39;x&#39;])
        
    def _remove_edge_cells(self, tile):
        &#34;&#34;&#34;
        Remove cells/objects that are touching the tile edge and if this edge is overlapping another tile.

        Parameters
        ----------
        tile: (tileLoader) tile to remove the object on
        verbose: option to display information

        Returns
        -------
        tileLoader with removed objects.
        &#34;&#34;&#34;

        shape = tile.apr.shape()
        s_min = np.array([np.nan, 0, 0])
        s_max = np.array([np.nan, shape[1], shape[2]])
        
        minc, maxc = pyapr.numerics.transform.find_objects(tile.apr, tile.parts_cc)

        for i in range(1, minc.shape[0]):
            if (minc[i, :] == s_min).any():
                ind = np.where(tile.parts_cc == i)
                for ii in ind[0]:
                    tile.parts_cc[ii] = 0
            if (maxc[i, :] == s_max).any():
                ind = np.where(tile.parts_cc == i)
                for ii in ind[0]:
                    tile.parts_cc[ii] = 0

        return tile

    def _merge_cells(self, tile, lowe_ratio, distance_max):
        &#34;&#34;&#34;
        Function to merge cells on a tile to the final cells list and remove duplicate.

        Parameters
        ----------
        tile: (tileLoader) tile from which to merge cells
        lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                            above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                            a second detection on the neighboring tile.
        distance_max: (float) maximum distance in pixel for two cells to be considered the same.

        Returns
        -------
        None
        &#34;&#34;&#34;

        r1 = np.max(self.cells, axis=0)
        r2 = self._get_tile_position(tile.row, tile.col)

        v_size = np.array(tile.apr.shape())

        # Define the overlapping area
        overlap_i = r2
        overlap_f = np.min((r1 + v_size, r2 + v_size), axis=0)

        # Retrieve cell centers
        cells2 = pyapr.numerics.transform.find_label_centers(tile.apr, tile.parts_cc, tile.parts)
        cells2 += r2

        # Filter cells to keep only those on the overlapping area
        for i in range(3):
            if i == 0:
                ind = np.where(self.cells[:, i] &lt; overlap_i[i])[0]
            else:
                ind = np.concatenate((ind, np.where(self.cells[:, i] &lt; overlap_i[i])[0]))
            ind = np.concatenate((ind, np.where(self.cells[:, i] &gt; overlap_f[i])[0]))
        ind = np.unique(ind)

        cells1_out = self.cells[ind, :]
        cells1_overlap = np.delete(self.cells, ind, axis=0)

        for i in range(3):
            if i == 0:
                ind = np.where(cells2[:, i] &lt; overlap_i[i])[0]
            else:
                ind = np.concatenate((ind, np.where(cells2[:, i] &lt; overlap_i[i])[0]))
            ind = np.concatenate((ind, np.where(cells2[:, i] &gt; overlap_f[i])[0]))
        ind = np.unique(ind)

        cells2_out = cells2[ind, :]
        cells2_overlap = np.delete(cells2, ind, axis=0)

        cells_filtered_overlap = self._filter_cells_flann(cells1_overlap,
                                                          cells2_overlap,
                                                          lowe_ratio=lowe_ratio,
                                                          distance_max=distance_max)

        self.cells = np.vstack((cells1_out, cells2_out, cells_filtered_overlap))

    def _get_tile_position(self, row, col):
        &#34;&#34;&#34;
        Function to get the absolute tile position defined by it&#39;s coordinate in the multitile set.

        Parameters
        ----------
        row: (int) row number
        col: (int) column number

        Returns
        -------
        (np.array) tile absolute position
        &#34;&#34;&#34;

        df = self.database
        tile_df = df[(df[&#39;row&#39;] == row) &amp; (df[&#39;col&#39;] == col)]
        px = tile_df[&#39;ABS_H&#39;].values[0]
        py = tile_df[&#39;ABS_V&#39;].values[0]
        pz = tile_df[&#39;ABS_D&#39;].values[0]

        return np.array([pz, py, px])

    def _filter_cells_flann(self, c1, c2, lowe_ratio=0.7, distance_max=5):
        &#34;&#34;&#34;
        Remove cells duplicate using Flann criteria and distance threshold.

        Parameters
        ----------
        c1: (np.array) array containing the first set cells coordinates
        c2: (np.array) array containing the second set cells coordinates
        lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                            above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                            a second detection on the neighboring tile.
        distance_max: (float) maximum distance in pixel for two cells to be considered the same.
        verbose: (bool) control function verbosity

        Returns
        -------
        (np.array) array containing the merged sets without the duplicates.
        &#34;&#34;&#34;

        if lowe_ratio &lt; 0 or lowe_ratio &gt; 1:
            raise ValueError(&#39;Lowe ratio is {}, expected between 0 and 1.&#39;.format(lowe_ratio))

        # Match cells descriptors by using Flann method
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=4)
        search_params = dict(checks=100)
        flann = cv.FlannBasedMatcher(index_params, search_params)
        matches = flann.knnMatch(np.float32(c1), np.float32(c2), k=2)
        # store all the good matches as per Lowe&#39;s ratio test.
        good = []
        for m, n in matches:
            if m.distance &lt; lowe_ratio*n.distance and m.distance &lt; distance_max:
                good.append(m)

        # Remove cells that are present in both volumes
        ind_c1 = [m.queryIdx for m in good]
        ind_c2 = [m.trainIdx for m in good]

        # For now I just remove the cells in c2 but merging strategies can be better
        c2 = np.delete(c2, ind_c2, axis=0)

        # Display info
        if self.verbose:
            print(&#39;{:0.2f}% of cells were removed.&#39;.format(len(ind_c2)/(c1.shape[0]+c2.shape[0]-len(ind_c2))*100))

        return np.vstack((c1, c2))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pipapr.segmenter.tileCells.extract_and_merge_cells"><code class="name flex">
<span>def <span class="ident">extract_and_merge_cells</span></span>(<span>self, lowe_ratio=0.7, distance_max=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to extract cell positions in each tile and merging across all tiles.
Identical cells on overlapping area are automatically detected using Flann method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>lowe_ratio</code></strong> :&ensp;<code>(float) ratio</code> of <code>the second nearest neighbor distance / nearest neighbor distance</code></dt>
<dd>above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
a second detection on the neighboring tile.</dd>
</dl>
<p>distance_max: (float) maximum distance in pixel for two cells to be considered the same.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_and_merge_cells(self, lowe_ratio=0.7, distance_max=5):
    &#34;&#34;&#34;
    Function to extract cell positions in each tile and merging across all tiles.
    Identical cells on overlapping area are automatically detected using Flann method.

    Parameters
    ----------
    lowe_ratio: (float) ratio of the second nearest neighbor distance / nearest neighbor distance
                        above lowe_ratio, the cell is supposed to be unique. Below lowe_ratio, it might have
                        a second detection on the neighboring tile.
    distance_max: (float) maximum distance in pixel for two cells to be considered the same.

    Returns
    -------
    None
    &#34;&#34;&#34;
    
    for tile in tqdm(self.tiles, desc=&#39;Extracting and merging cells..&#39;):
        tile.load_tile()
        tile.load_segmentation()
        
        # Remove objects on the edge
        tile = self._remove_edge_cells(tile)

        # Initialized merged cells for the first tile
        if self.cells is None:
            self.cells = pyapr.numerics.transform.find_label_centers(tile.apr, tile.parts_cc, tile.parts)
            self.cells += self._get_tile_position(tile.row, tile.col)
        # Then merge the rest on the first tile
        else:
            self._merge_cells(tile, lowe_ratio=lowe_ratio, distance_max=distance_max)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileCells.save_cells"><code class="name flex">
<span>def <span class="ident">save_cells</span></span>(<span>self, output_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Save cells as a CSV file.</p>
<h2 id="parameters">Parameters</h2>
<p>output_path: (str) path for saving the CSV file.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_cells(self, output_path):
    &#34;&#34;&#34;
    Save cells as a CSV file.

    Parameters
    ----------
    output_path: (str) path for saving the CSV file.

    Returns
    -------
    None
    &#34;&#34;&#34;

    pd.DataFrame(self.cells).to_csv(output_path, header=[&#39;z&#39;, &#39;y&#39;, &#39;x&#39;])</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pipapr.segmenter.tileSegmenter"><code class="flex name class">
<span>class <span class="ident">tileSegmenter</span></span>
<span>(</span><span>clf, func_to_compute_features, func_to_get_cc, verbose)</span>
</code></dt>
<dd>
<div class="desc"><p>Class used to segment tiles. It is instantiated with a tileLoader object, a previously trained classifier,
a function to compute features (the same features used to train the classifier and a function to get the
post processed connected component for the classifier output.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt>tile: (tileLoader) tile object for loading the tile (or containing the preloaded tile).</dt>
<dt><strong><code>path_classifier</code></strong> :&ensp;<code>(str) path to pre-trained classifier</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>func_to_compute_features</code></strong> :&ensp;<code>(func) function to compute the features on ParticleData. Must be the same set of</code></dt>
<dd>as the one used to train the classifier.</dd>
<dt><strong><code>func_to_get_cc</code></strong> :&ensp;<code>(func) function to post process the segmentation map into a connected component (each cell has</code></dt>
<dd>a unique id)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class tileSegmenter():
    &#34;&#34;&#34;
    Class used to segment tiles. It is instantiated with a tileLoader object, a previously trained classifier,
    a function to compute features (the same features used to train the classifier and a function to get the
    post processed connected component for the classifier output.

    &#34;&#34;&#34;

    def __init__(self, clf, func_to_compute_features, func_to_get_cc, verbose):
        &#34;&#34;&#34;

        Parameters
        ----------
        tile: (tileLoader) tile object for loading the tile (or containing the preloaded tile).
        path_classifier: (str) path to pre-trained classifier
        func_to_compute_features: (func) function to compute the features on ParticleData. Must be the same set of
                                        as the one used to train the classifier.
        func_to_get_cc: (func) function to post process the segmentation map into a connected component (each cell has
                                        a unique id)
        &#34;&#34;&#34;

        # Store classifier
        self.clf = clf
        # Store function to compute features
        self.func_to_compute_features = func_to_compute_features
        # Store post processing steps
        self.func_to_get_cc = func_to_get_cc
        # Verbose
        self.verbose = verbose

    @classmethod
    def from_trainer(cls,
                     trainer,
                     verbose=True):
        &#34;&#34;&#34;
        Instantiate tileSegmenter object with a tileTrainer object.

        Parameters
        ----------
        trainer: (pipapr.segmenter.tileTrainer) trainer object previously trained for segmentation
        verbose: (bool) control function output

        Returns
        -------
        tileSegmenter object
        &#34;&#34;&#34;

        return cls(clf=trainer.clf,
                   func_to_compute_features=trainer.func_to_compute_features,
                   func_to_get_cc=trainer.func_to_get_cc,
                   verbose=verbose)

    @classmethod
    def from_classifier(cls,
                        classifier,
                        func_to_compute_features,
                        func_to_get_cc=None,
                        verbose=True):
        &#34;&#34;&#34;
        Instantiate tileSegmenter object with a classifier, function to compute the features and to get the
        connected components.

        Parameters
        ----------
        classifier
        func_to_compute_features: (func) function to compute features used by the classifier to perform
                                    the segmentation.
        func_to_get_cc: (func) function to compute the connected component from the classifier prediction.
        verbose: (bool) control function output.

        Returns
        -------
        tileSegmenter object
        &#34;&#34;&#34;

        if isinstance(classifier, str):
            clf = load(classifier)
        else:
            clf = classifier

        return cls(clf=clf,
                   func_to_compute_features=func_to_compute_features,
                   func_to_get_cc=func_to_get_cc,
                   verbose=verbose)

    def compute_segmentation(self, tile: pipapr.loader.tileLoader,
                             save_cc=True, save_mask=False):
        &#34;&#34;&#34;
        Compute the segmentation and stores the result as an independent APR.

        Parameters
        ----------
        verbose: (bool) control the verbosity of the function to print some info

        Returns
        -------
        None
        &#34;&#34;&#34;

        if tile.apr is None:
            tile.load_tile()

        # Compute features on APR
        if self.verbose:
            t = time()
            print(&#39;Computing features on APR&#39;)
        f = self.func_to_compute_features(tile.apr, tile.parts)
        self.filtered_APR = f
        if self.verbose:
            print(&#39;Features computation took {:0.2f} s.&#39;.format(time()-t))

        # Predict particle class
        parts_pred = _predict_on_APR_block(f, self.clf, verbose=self.verbose)
        if self.verbose:
            # Display inference info
            print(&#39;\n****** INFERENCE RESULTS ******&#39;)
            for l in self.clf.classes_:
                print(&#39;Class {}: {} particles ({:0.2f}%)&#39;.format(l, np.sum(parts_pred == l),
                                                      np.sum(parts_pred == l) / len(parts_pred) * 100))
            print(&#39;*******************************&#39;)

        # Compute connected component from classification
        if self.func_to_get_cc is not None:
            cc = self.func_to_get_cc(tile.apr, parts_pred)
            tile.parts_cc = cc

        # Save results
        if save_mask:
            self._save_segmentation(tile.path, name=&#39;segmentation mask&#39;, parts=parts_pred)
        if save_cc:
            self._save_segmentation(tile.path, name=&#39;segmentation cc&#39;, parts=cc)

        tile.parts_mask = parts_pred

    def _save_segmentation(self, path, name, parts):
        &#34;&#34;&#34;
        Save segmentation particles by appending the original APR file.

        Parameters
        ----------
        parts: (pyapr.ParticleData) particles to save. Note that the APR tree should be the same otherwise the data
                                    will be inconsistent and not readable.

        Returns
        -------
        None
        &#34;&#34;&#34;
        aprfile = pyapr.io.APRFile()
        aprfile.set_read_write_tree(True)
        aprfile.open(path, &#39;READWRITE&#39;)
        aprfile.write_particles(name, parts, t=0)
        aprfile.close()</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pipapr.segmenter.tileSegmenter.from_classifier"><code class="name flex">
<span>def <span class="ident">from_classifier</span></span>(<span>classifier, func_to_compute_features, func_to_get_cc=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate tileSegmenter object with a classifier, function to compute the features and to get the
connected components.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>classifier</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>func_to_compute_features</code></strong> :&ensp;<code>(func) function to compute features used by the classifier to perform</code></dt>
<dd>the segmentation.</dd>
</dl>
<p>func_to_get_cc: (func) function to compute the connected component from the classifier prediction.
verbose: (bool) control function output.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pipapr.segmenter.tileSegmenter" href="#pipapr.segmenter.tileSegmenter">tileSegmenter</a> object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_classifier(cls,
                    classifier,
                    func_to_compute_features,
                    func_to_get_cc=None,
                    verbose=True):
    &#34;&#34;&#34;
    Instantiate tileSegmenter object with a classifier, function to compute the features and to get the
    connected components.

    Parameters
    ----------
    classifier
    func_to_compute_features: (func) function to compute features used by the classifier to perform
                                the segmentation.
    func_to_get_cc: (func) function to compute the connected component from the classifier prediction.
    verbose: (bool) control function output.

    Returns
    -------
    tileSegmenter object
    &#34;&#34;&#34;

    if isinstance(classifier, str):
        clf = load(classifier)
    else:
        clf = classifier

    return cls(clf=clf,
               func_to_compute_features=func_to_compute_features,
               func_to_get_cc=func_to_get_cc,
               verbose=verbose)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileSegmenter.from_trainer"><code class="name flex">
<span>def <span class="ident">from_trainer</span></span>(<span>trainer, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate tileSegmenter object with a tileTrainer object.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>trainer</code></strong> :&ensp;<code>(<a title="pipapr.segmenter.tileTrainer" href="#pipapr.segmenter.tileTrainer">tileTrainer</a>) trainer object previously trained for segmentation</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>(bool) control function output</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pipapr.segmenter.tileSegmenter" href="#pipapr.segmenter.tileSegmenter">tileSegmenter</a> object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_trainer(cls,
                 trainer,
                 verbose=True):
    &#34;&#34;&#34;
    Instantiate tileSegmenter object with a tileTrainer object.

    Parameters
    ----------
    trainer: (pipapr.segmenter.tileTrainer) trainer object previously trained for segmentation
    verbose: (bool) control function output

    Returns
    -------
    tileSegmenter object
    &#34;&#34;&#34;

    return cls(clf=trainer.clf,
               func_to_compute_features=trainer.func_to_compute_features,
               func_to_get_cc=trainer.func_to_get_cc,
               verbose=verbose)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pipapr.segmenter.tileSegmenter.compute_segmentation"><code class="name flex">
<span>def <span class="ident">compute_segmentation</span></span>(<span>self, tile: <a title="pipapr.loader.tileLoader" href="loader.html#pipapr.loader.tileLoader">tileLoader</a>, save_cc=True, save_mask=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the segmentation and stores the result as an independent APR.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>(bool) control the verbosity</code> of <code>the function to print some info</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_segmentation(self, tile: pipapr.loader.tileLoader,
                         save_cc=True, save_mask=False):
    &#34;&#34;&#34;
    Compute the segmentation and stores the result as an independent APR.

    Parameters
    ----------
    verbose: (bool) control the verbosity of the function to print some info

    Returns
    -------
    None
    &#34;&#34;&#34;

    if tile.apr is None:
        tile.load_tile()

    # Compute features on APR
    if self.verbose:
        t = time()
        print(&#39;Computing features on APR&#39;)
    f = self.func_to_compute_features(tile.apr, tile.parts)
    self.filtered_APR = f
    if self.verbose:
        print(&#39;Features computation took {:0.2f} s.&#39;.format(time()-t))

    # Predict particle class
    parts_pred = _predict_on_APR_block(f, self.clf, verbose=self.verbose)
    if self.verbose:
        # Display inference info
        print(&#39;\n****** INFERENCE RESULTS ******&#39;)
        for l in self.clf.classes_:
            print(&#39;Class {}: {} particles ({:0.2f}%)&#39;.format(l, np.sum(parts_pred == l),
                                                  np.sum(parts_pred == l) / len(parts_pred) * 100))
        print(&#39;*******************************&#39;)

    # Compute connected component from classification
    if self.func_to_get_cc is not None:
        cc = self.func_to_get_cc(tile.apr, parts_pred)
        tile.parts_cc = cc

    # Save results
    if save_mask:
        self._save_segmentation(tile.path, name=&#39;segmentation mask&#39;, parts=parts_pred)
    if save_cc:
        self._save_segmentation(tile.path, name=&#39;segmentation cc&#39;, parts=cc)

    tile.parts_mask = parts_pred</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pipapr.segmenter.tileTrainer"><code class="flex name class">
<span>class <span class="ident">tileTrainer</span></span>
<span>(</span><span>tile: <a title="pipapr.loader.tileLoader" href="loader.html#pipapr.loader.tileLoader">tileLoader</a>, func_to_compute_features, func_to_get_cc=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class used to train a classifier that works directly on APR data. It uses Napari to manually add labels.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class tileTrainer():
    &#34;&#34;&#34;
    Class used to train a classifier that works directly on APR data. It uses Napari to manually add labels.

    &#34;&#34;&#34;

    def __init__(self,
                 tile: pipapr.loader.tileLoader,
                 func_to_compute_features,
                 func_to_get_cc=None):

        tile.load_tile()
        self.tile = tile
        self.apr = tile.apr
        self.parts = tile.parts
        self.apr_it = self.apr.iterator()
        self.shape = tile.apr.shape()
        self.func_to_compute_features = func_to_compute_features
        self.func_to_get_cc = func_to_get_cc

        self.labels_manual = None
        self.pixel_list = None
        self.labels = None
        self.use_sparse_labels = None
        self.parts_train_idx = None
        self.clf = None
        self.parts_mask = None
        self.parts_cc = None
        self.f = None

    def manually_annotate(self, use_sparse_labels=True, **kwargs):
        &#34;&#34;&#34;
        Manually annotate dataset using Napari.

        Parameters
        ----------
        use_sparse_labels: (bool) use sparse array to store the labels (memory efficient but slower graphics)

        Returns
        -------
        None
        &#34;&#34;&#34;
        self.sparse = use_sparse_labels

        if self.sparse:
            # We create a sparse array that supports inserting data (COO does not)
            self.labels_manual = sparse.DOK(shape=self.shape, dtype=&#39;uint8&#39;)
        else:
            self.labels_manual = np.empty(self.shape, dtype=&#39;uint8&#39;)

        # We call napari with the APRSlicer and the sparse array for storing the manual annotations
        viewer = napari.Viewer()
        image_layer = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts), **kwargs)
        viewer.add_layer(image_layer)
        viewer.add_labels(self.labels_manual)
        viewer.show(block=True)

        # We extract labels and pixel coordinate from the sparse array
        if self.sparse:
            self.labels_manual = self.labels_manual.to_coo()
        else:
            self.labels_manual = sparse.COO.from_numpy(self.labels_manual)

        self.pixel_list = self.labels_manual.coords.T
        self.labels = self.labels_manual.data

    def add_annotations(self, use_sparse_labels=True, **kwargs):
        &#34;&#34;&#34;
        Add annotations on previously annotated dataset.

        Parameters
        ----------
        use_sparse_labels: (bool) use sparse array to store the labels (memory efficient but slower graphics)

        Returns
        -------
        None
        &#34;&#34;&#34;

        self.sparse = use_sparse_labels

        if self.sparse:
            # We create a sparse array that supports inserting data (COO does not)
            self.labels_manual = sparse.DOK(self.labels_manual)
        else:
            self.labels_manual = self.labels_manual.todense()

        # We call napari with the APRSlicer and the sparse array for storing the manual annotations
        viewer = napari.Viewer()
        image_layer = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts), **kwargs)
        viewer.add_layer(image_layer)
        viewer.add_labels(self.labels_manual)
        viewer.show(block=True)

        # We extract labels and pixel coordinate from the sparse array
        if self.sparse:
            self.labels_manual = self.labels_manual.to_coo()
        else:
            self.labels_manual = sparse.COO.from_numpy(self.labels_manual)

        self.pixel_list = self.labels_manual.coords.T
        self.labels = self.labels_manual.data

    def save_labels(self, path=None):
        &#34;&#34;&#34;
        Save labels as numpy array with columns corresponding to [z, y, x, label].

        Parameters
        ----------
        path: (str) path to save labels. By default it saves them in the data root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;

        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;manual_labels.npy&#39;)

        to_be_saved = np.hstack((self.pixel_list, self.labels[:, np.newaxis]))
        np.save(path, to_be_saved)

    def load_labels(self, path=None):
        &#34;&#34;&#34;
        Load previously saved labels as numpy array with columns corresponding to [z, y, x, label].

        Parameters
        ----------
        path: (str) path to load the saved labels. By default it loads them in the data root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;
        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;manual_labels.npy&#39;)

        data = np.load(path)
        self.pixel_list = data[:, :-1]
        self.labels = data[:, -1]
        self.labels_manual = sparse.COO(coords=self.pixel_list.T, data=self.labels)

    def train_classifier(self, verbose=True):
        &#34;&#34;&#34;
        Train the classifier for segmentation.

        Parameters
        ----------
        verbose: (bool) option to print out information.

        Returns
        -------
        None
        &#34;&#34;&#34;
        if self.pixel_list is None:
            raise ValueError(&#39;Error: annotate dataset or load annotations before training classifier.&#39;)

        from sklearn import preprocessing
        from sklearn.pipeline import make_pipeline
        from sklearn.ensemble import RandomForestClassifier

        # We sample pixel_list on APR grid
        self._sample_pixel_list_on_APR()

        # We remove ambiguous case where a particle was labeled differently
        self._remove_ambiguities(verbose=verbose)

        # We compute features and train the classifier
        if self.f is None:
            f = self.func_to_compute_features(self.apr, self.parts)

        # Fetch data that was manually labelled
        x = f[self.parts_train_idx]
        y = self.parts_labels

        # Train random forest
        clf = make_pipeline(preprocessing.StandardScaler(with_mean=True, with_std=True),
                            RandomForestClassifier(n_estimators=10, class_weight=&#39;balanced&#39;))
        t = time()
        clf.fit(x, y.ravel())
        print(&#39;Training took {} s.\n&#39;.format(time() - t))

        x_pred = clf.predict(x)

        # Display training info
        if verbose:
            print(&#39;\n****** TRAINING RESULTS ******&#39;)
            print(&#39;Total accuracy: {:0.2f}%&#39;.format(np.sum(x_pred == y) / y.size * 100))
            for l in self.unique_labels:
                print(&#39;Class {} accuracy: {:0.2f}% ({} cell particles)&#39;.format(l,
                    np.sum((x_pred == y) * (y == l)) / np.sum(y == l) * 100, np.sum(y == l)))
            print(&#39;******************************\n&#39;)

        self.clf = clf
        self.f = f

    def segment_training_tile(self, bg_label=None, display_result=True, verbose=True):
        &#34;&#34;&#34;
        Apply classifier to the whole tile and display segmentation results using Napari.

        Parameters
        ----------
        display_result: (bool) option to display segmentation results using Napari
        verbose: (bool) option to print out information.

        Returns
        -------
        None
        &#34;&#34;&#34;

        # Apply on whole dataset
        if self.parts_mask is None:
            parts_pred = _predict_on_APR_block(self.f, self.clf, verbose=verbose)
            self.parts_mask = parts_pred

        if (self.func_to_get_cc is not None) and self.parts_cc is None:
            self.parts_cc = self.func_to_get_cc(self.apr, self.parts_mask.copy())

        # Display inference info
        if verbose:
            print(&#39;\n****** INFERENCE RESULTS ******&#39;)
            for l in self.unique_labels:
                print(&#39;Class {}: {} cell particles ({:0.2f}%)&#39;.format(l, np.sum(self.parts_mask == l),
                                                            np.sum(self.parts_mask == l) / len(self.parts_mask) * 100))
            print(&#39;******************************\n&#39;)

        # Display segmentation using Napari
        if display_result:
            if self.parts_cc is not None:
                pipapr.viewer.display_segmentation(self.apr, self.parts, self.parts_cc)
            elif bg_label is not None:
                parts_pred = np.array(self.parts_mask.copy())
                parts_pred[parts_pred == bg_label] = 0
                parts_pred = pyapr.ShortParticles(parts_pred)
                pipapr.viewer.display_segmentation(self.apr, self.parts, parts_pred)

    def display_training_annotations(self, **kwargs):
        &#34;&#34;&#34;
        Display manual annotations and their sampling on APR grid (if available).

        Returns
        -------
        None
        &#34;&#34;&#34;
        image_nap = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts),
                                        opacity=0.7, **kwargs)
        viewer = napari.Viewer()
        viewer.add_layer(image_nap)
        viewer.add_labels(self.labels_manual, name=&#39;Manual labels&#39;, opacity=0.5)
        if self.parts_labels is not None:
            mask = np.zeros_like(self.parts, dtype=&#39;uint16&#39;)
            mask[self.parts_train_idx] = self.parts_labels
            label_nap = napari.layers.Labels(data=pyapr.data_containers.APRSlicer(self.apr, pyapr.ShortParticles(mask)),
                                             name=&#39;APR labels&#39;, opacity=0.5)
            viewer.add_layer(label_nap)
        napari.run()

    def apply_on_tile(self, tile, bg_label=None, func_to_get_cc=None, display_result=True, verbose=True):
        &#34;&#34;&#34;
        Apply classifier to the whole tile and display segmentation results using Napari.

        Parameters
        ----------
        display_result: (bool) option to display segmentation results using Napari
        verbose: (bool) option to print out information.

        Returns
        -------
        None
        &#34;&#34;&#34;

        # Apply on whole dataset
        if tile.apr is None:
            tile.load_tile()
        f = self.func_to_compute_features(tile.apr, tile.parts)
        parts_pred = _predict_on_APR_block(f, self.clf, verbose=verbose)
        tile.parts_mask = parts_pred.copy()

        # Display inference info
        if verbose:
            print(&#39;\n****** INFERENCE RESULTS ******&#39;)
            for l in self.unique_labels:
                print(&#39;Class {}: {} cell particles ({:0.2f}%)&#39;.format(l, np.sum(parts_pred == l),
                                                            np.sum(parts_pred == l) / len(parts_pred) * 100))
            print(&#39;******************************\n&#39;)

        # Display segmentation using Napari
        if display_result:
            if func_to_get_cc is not None:
                tile.parts_cc = func_to_get_cc(tile.apr, parts_pred)
                pipapr.viewer.display_segmentation(self.apr, self.parts, tile.parts_cc)
            elif bg_label is not None:
                parts_pred = np.array(parts_pred)
                parts_pred[parts_pred==bg_label] = 0
                parts_pred = pyapr.ShortParticles(parts_pred)
                pipapr.viewer.display_segmentation(self.apr, self.parts, parts_pred)

    def save_classifier(self, path=None):
        &#34;&#34;&#34;
        Save the trained classifier.

        Parameters
        ----------
        path: (str) path for saving the classifier. By default, it is saved in the data root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;
        from joblib import dump

        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;random_forest_n100.joblib&#39;)

        dump(self.clf, path)

    def load_classifier(self, path=None):
        &#34;&#34;&#34;
        Load a trained classifier.

        Parameters
        ----------
        path: (str) path for loading the classifier. By default, it is loaded from root folder.

        Returns
        -------
        None
        &#34;&#34;&#34;
        from joblib import load

        if path is None:
            path = os.path.join(self.tile.folder_root, &#39;random_forest_n100.joblib&#39;)

        self.clf = load(path)

    def display_features(self):
        &#34;&#34;&#34;
        Display the computed features.

        &#34;&#34;&#34;
        if self.f is None:
            raise TypeError(&#39;Error: filters can&#39;&#39;t be displayed because they were not computed&#39;)

        viewer = napari.Viewer()
        for i in range(f.shape[1]):
            viewer.add_layer(pipapr.viewer.apr_to_napari_Image(self.apr, pyapr.FloatParticles(f[:, i])))
        napari.run()

    def _remove_ambiguities(self, verbose):
        &#34;&#34;&#34;
        Remove particles that have been labelled with different labels.

        Parameters
        ----------
        verbose: (bool) option to print out information.

        Returns
        -------

        &#34;&#34;&#34;
        if self.parts_train_idx is None:
            raise ValueError(&#39;Error: train classifier before removing ambiguities.&#39;)

        idx_unique = np.unique(self.parts_train_idx)

        parts_train = []
        parts_labels = []

        cnt = 0
        for idx in idx_unique:
            local_labels = self.labels[self.parts_train_idx==idx]
            is_same, l = self._are_labels_the_same(local_labels)
            if is_same:
                # If labels are the same we assign it
                parts_labels.append(l)
                parts_train.append(idx)
            else:
                cnt += 1

        self.parts_train_idx = np.array(parts_train)
        self.parts_labels = np.array(parts_labels)
        self.unique_labels = np.unique(self.parts_labels)

        if verbose:
            print(&#39;\n********* ANNOTATIONS ***********&#39;)
            print(&#39;{} ambiguous particles were removed.&#39;.format(cnt))
            print(&#39;{} particles were labeled.&#39;.format(self.parts_labels.shape[0]))
            for l in self.unique_labels:
                print(&#39;{} particles ({:0.2f}%) were labeled as {}.&#39;.format(np.sum(self.parts_labels==l),
                                                                       100*np.sum(self.parts_labels==l)/self.parts_labels.shape[0],
                                                                        l))
            print(&#39;***********************************\n&#39;)

    def _sample_pixel_list_on_APR(self):
        &#34;&#34;&#34;
        Convert manual annotations coordinates from pixel to APR.

        Returns
        -------
        None
        &#34;&#34;&#34;
        self.parts_train_idx = np.empty(self.pixel_list.shape[0], dtype=&#39;uint64&#39;)

        for i in tqdm(range(self.pixel_list.shape[0]), desc=&#39;Sampling labels on APR.&#39;):
            idx = self._find_particle(self.pixel_list[i, :])

            self.parts_train_idx[i] = idx

    def _find_particle(self, coords):
        &#34;&#34;&#34;
        Find particle index corresponding to pixel location coords.

        Parameters
        ----------
        coords: (array) pixel coordinate [z, y, x]

        Returns
        -------
        idx: (int) particle index
        &#34;&#34;&#34;
        # TODO: @JOEL PUT THIS IN C++ PLEASE
        for level in range(self.apr_it.level_min(), self.apr_it.level_max()+1):
            particle_size = 2 ** (self.apr.level_max() - level)
            z_l, x_l, y_l = coords // particle_size
            for idx in range(self.apr_it.begin(level, z_l, x_l), self.apr_it.end()):
                if self.apr_it.y(idx) == y_l:
                    # if np.sqrt(np.sum((coords-np.array([z_l, x_l, y_l])*particle_size)**2))/particle_size &gt; np.sqrt(3):
                    #     print(&#39;ich&#39;)
                    return idx

    def _order_labels(self):
        &#34;&#34;&#34;
        Order pixel_list in z incresing order, then y increasing order and finally x increasing order.

        Returns
        -------
        None
        &#34;&#34;&#34;
        for d in range(3, 0):
            ind = np.argsort(self.pixel_list[:, d])
            self.pixel_list = self.pixel_list[ind]
            self.labels = self.labels[ind]

    @staticmethod
    def _are_labels_the_same(local_labels):
        &#34;&#34;&#34;
        Determine if manual labels in particle are the same and return the labels

        Parameters
        ----------
        local_labels: (array) particle labels

        Returns
        -------
        ((bool): True if labels are the same, (int) corresponding label)
        &#34;&#34;&#34;
        return ((local_labels == local_labels[0]).all(), local_labels[0])</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pipapr.segmenter.tileTrainer.add_annotations"><code class="name flex">
<span>def <span class="ident">add_annotations</span></span>(<span>self, use_sparse_labels=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Add annotations on previously annotated dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>use_sparse_labels</code></strong> :&ensp;<code>(bool) use sparse array to store the labels (memory efficient but slower graphics)</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_annotations(self, use_sparse_labels=True, **kwargs):
    &#34;&#34;&#34;
    Add annotations on previously annotated dataset.

    Parameters
    ----------
    use_sparse_labels: (bool) use sparse array to store the labels (memory efficient but slower graphics)

    Returns
    -------
    None
    &#34;&#34;&#34;

    self.sparse = use_sparse_labels

    if self.sparse:
        # We create a sparse array that supports inserting data (COO does not)
        self.labels_manual = sparse.DOK(self.labels_manual)
    else:
        self.labels_manual = self.labels_manual.todense()

    # We call napari with the APRSlicer and the sparse array for storing the manual annotations
    viewer = napari.Viewer()
    image_layer = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts), **kwargs)
    viewer.add_layer(image_layer)
    viewer.add_labels(self.labels_manual)
    viewer.show(block=True)

    # We extract labels and pixel coordinate from the sparse array
    if self.sparse:
        self.labels_manual = self.labels_manual.to_coo()
    else:
        self.labels_manual = sparse.COO.from_numpy(self.labels_manual)

    self.pixel_list = self.labels_manual.coords.T
    self.labels = self.labels_manual.data</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.apply_on_tile"><code class="name flex">
<span>def <span class="ident">apply_on_tile</span></span>(<span>self, tile, bg_label=None, func_to_get_cc=None, display_result=True, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply classifier to the whole tile and display segmentation results using Napari.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>display_result</code></strong> :&ensp;<code>(bool) option to display segmentation results using Napari</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>verbose: (bool) option to print out information.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_on_tile(self, tile, bg_label=None, func_to_get_cc=None, display_result=True, verbose=True):
    &#34;&#34;&#34;
    Apply classifier to the whole tile and display segmentation results using Napari.

    Parameters
    ----------
    display_result: (bool) option to display segmentation results using Napari
    verbose: (bool) option to print out information.

    Returns
    -------
    None
    &#34;&#34;&#34;

    # Apply on whole dataset
    if tile.apr is None:
        tile.load_tile()
    f = self.func_to_compute_features(tile.apr, tile.parts)
    parts_pred = _predict_on_APR_block(f, self.clf, verbose=verbose)
    tile.parts_mask = parts_pred.copy()

    # Display inference info
    if verbose:
        print(&#39;\n****** INFERENCE RESULTS ******&#39;)
        for l in self.unique_labels:
            print(&#39;Class {}: {} cell particles ({:0.2f}%)&#39;.format(l, np.sum(parts_pred == l),
                                                        np.sum(parts_pred == l) / len(parts_pred) * 100))
        print(&#39;******************************\n&#39;)

    # Display segmentation using Napari
    if display_result:
        if func_to_get_cc is not None:
            tile.parts_cc = func_to_get_cc(tile.apr, parts_pred)
            pipapr.viewer.display_segmentation(self.apr, self.parts, tile.parts_cc)
        elif bg_label is not None:
            parts_pred = np.array(parts_pred)
            parts_pred[parts_pred==bg_label] = 0
            parts_pred = pyapr.ShortParticles(parts_pred)
            pipapr.viewer.display_segmentation(self.apr, self.parts, parts_pred)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.display_features"><code class="name flex">
<span>def <span class="ident">display_features</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Display the computed features.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_features(self):
    &#34;&#34;&#34;
    Display the computed features.

    &#34;&#34;&#34;
    if self.f is None:
        raise TypeError(&#39;Error: filters can&#39;&#39;t be displayed because they were not computed&#39;)

    viewer = napari.Viewer()
    for i in range(f.shape[1]):
        viewer.add_layer(pipapr.viewer.apr_to_napari_Image(self.apr, pyapr.FloatParticles(f[:, i])))
    napari.run()</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.display_training_annotations"><code class="name flex">
<span>def <span class="ident">display_training_annotations</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Display manual annotations and their sampling on APR grid (if available).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_training_annotations(self, **kwargs):
    &#34;&#34;&#34;
    Display manual annotations and their sampling on APR grid (if available).

    Returns
    -------
    None
    &#34;&#34;&#34;
    image_nap = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts),
                                    opacity=0.7, **kwargs)
    viewer = napari.Viewer()
    viewer.add_layer(image_nap)
    viewer.add_labels(self.labels_manual, name=&#39;Manual labels&#39;, opacity=0.5)
    if self.parts_labels is not None:
        mask = np.zeros_like(self.parts, dtype=&#39;uint16&#39;)
        mask[self.parts_train_idx] = self.parts_labels
        label_nap = napari.layers.Labels(data=pyapr.data_containers.APRSlicer(self.apr, pyapr.ShortParticles(mask)),
                                         name=&#39;APR labels&#39;, opacity=0.5)
        viewer.add_layer(label_nap)
    napari.run()</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.load_classifier"><code class="name flex">
<span>def <span class="ident">load_classifier</span></span>(<span>self, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a trained classifier.</p>
<h2 id="parameters">Parameters</h2>
<p>path: (str) path for loading the classifier. By default, it is loaded from root folder.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_classifier(self, path=None):
    &#34;&#34;&#34;
    Load a trained classifier.

    Parameters
    ----------
    path: (str) path for loading the classifier. By default, it is loaded from root folder.

    Returns
    -------
    None
    &#34;&#34;&#34;
    from joblib import load

    if path is None:
        path = os.path.join(self.tile.folder_root, &#39;random_forest_n100.joblib&#39;)

    self.clf = load(path)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.load_labels"><code class="name flex">
<span>def <span class="ident">load_labels</span></span>(<span>self, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Load previously saved labels as numpy array with columns corresponding to [z, y, x, label].</p>
<h2 id="parameters">Parameters</h2>
<p>path: (str) path to load the saved labels. By default it loads them in the data root folder.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_labels(self, path=None):
    &#34;&#34;&#34;
    Load previously saved labels as numpy array with columns corresponding to [z, y, x, label].

    Parameters
    ----------
    path: (str) path to load the saved labels. By default it loads them in the data root folder.

    Returns
    -------
    None
    &#34;&#34;&#34;
    if path is None:
        path = os.path.join(self.tile.folder_root, &#39;manual_labels.npy&#39;)

    data = np.load(path)
    self.pixel_list = data[:, :-1]
    self.labels = data[:, -1]
    self.labels_manual = sparse.COO(coords=self.pixel_list.T, data=self.labels)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.manually_annotate"><code class="name flex">
<span>def <span class="ident">manually_annotate</span></span>(<span>self, use_sparse_labels=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Manually annotate dataset using Napari.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>use_sparse_labels</code></strong> :&ensp;<code>(bool) use sparse array to store the labels (memory efficient but slower graphics)</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def manually_annotate(self, use_sparse_labels=True, **kwargs):
    &#34;&#34;&#34;
    Manually annotate dataset using Napari.

    Parameters
    ----------
    use_sparse_labels: (bool) use sparse array to store the labels (memory efficient but slower graphics)

    Returns
    -------
    None
    &#34;&#34;&#34;
    self.sparse = use_sparse_labels

    if self.sparse:
        # We create a sparse array that supports inserting data (COO does not)
        self.labels_manual = sparse.DOK(shape=self.shape, dtype=&#39;uint8&#39;)
    else:
        self.labels_manual = np.empty(self.shape, dtype=&#39;uint8&#39;)

    # We call napari with the APRSlicer and the sparse array for storing the manual annotations
    viewer = napari.Viewer()
    image_layer = napari.layers.Image(data=pyapr.data_containers.APRSlicer(self.apr, self.parts), **kwargs)
    viewer.add_layer(image_layer)
    viewer.add_labels(self.labels_manual)
    viewer.show(block=True)

    # We extract labels and pixel coordinate from the sparse array
    if self.sparse:
        self.labels_manual = self.labels_manual.to_coo()
    else:
        self.labels_manual = sparse.COO.from_numpy(self.labels_manual)

    self.pixel_list = self.labels_manual.coords.T
    self.labels = self.labels_manual.data</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.save_classifier"><code class="name flex">
<span>def <span class="ident">save_classifier</span></span>(<span>self, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the trained classifier.</p>
<h2 id="parameters">Parameters</h2>
<p>path: (str) path for saving the classifier. By default, it is saved in the data root folder.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_classifier(self, path=None):
    &#34;&#34;&#34;
    Save the trained classifier.

    Parameters
    ----------
    path: (str) path for saving the classifier. By default, it is saved in the data root folder.

    Returns
    -------
    None
    &#34;&#34;&#34;
    from joblib import dump

    if path is None:
        path = os.path.join(self.tile.folder_root, &#39;random_forest_n100.joblib&#39;)

    dump(self.clf, path)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.save_labels"><code class="name flex">
<span>def <span class="ident">save_labels</span></span>(<span>self, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save labels as numpy array with columns corresponding to [z, y, x, label].</p>
<h2 id="parameters">Parameters</h2>
<p>path: (str) path to save labels. By default it saves them in the data root folder.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_labels(self, path=None):
    &#34;&#34;&#34;
    Save labels as numpy array with columns corresponding to [z, y, x, label].

    Parameters
    ----------
    path: (str) path to save labels. By default it saves them in the data root folder.

    Returns
    -------
    None
    &#34;&#34;&#34;

    if path is None:
        path = os.path.join(self.tile.folder_root, &#39;manual_labels.npy&#39;)

    to_be_saved = np.hstack((self.pixel_list, self.labels[:, np.newaxis]))
    np.save(path, to_be_saved)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.segment_training_tile"><code class="name flex">
<span>def <span class="ident">segment_training_tile</span></span>(<span>self, bg_label=None, display_result=True, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply classifier to the whole tile and display segmentation results using Napari.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>display_result</code></strong> :&ensp;<code>(bool) option to display segmentation results using Napari</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>verbose: (bool) option to print out information.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def segment_training_tile(self, bg_label=None, display_result=True, verbose=True):
    &#34;&#34;&#34;
    Apply classifier to the whole tile and display segmentation results using Napari.

    Parameters
    ----------
    display_result: (bool) option to display segmentation results using Napari
    verbose: (bool) option to print out information.

    Returns
    -------
    None
    &#34;&#34;&#34;

    # Apply on whole dataset
    if self.parts_mask is None:
        parts_pred = _predict_on_APR_block(self.f, self.clf, verbose=verbose)
        self.parts_mask = parts_pred

    if (self.func_to_get_cc is not None) and self.parts_cc is None:
        self.parts_cc = self.func_to_get_cc(self.apr, self.parts_mask.copy())

    # Display inference info
    if verbose:
        print(&#39;\n****** INFERENCE RESULTS ******&#39;)
        for l in self.unique_labels:
            print(&#39;Class {}: {} cell particles ({:0.2f}%)&#39;.format(l, np.sum(self.parts_mask == l),
                                                        np.sum(self.parts_mask == l) / len(self.parts_mask) * 100))
        print(&#39;******************************\n&#39;)

    # Display segmentation using Napari
    if display_result:
        if self.parts_cc is not None:
            pipapr.viewer.display_segmentation(self.apr, self.parts, self.parts_cc)
        elif bg_label is not None:
            parts_pred = np.array(self.parts_mask.copy())
            parts_pred[parts_pred == bg_label] = 0
            parts_pred = pyapr.ShortParticles(parts_pred)
            pipapr.viewer.display_segmentation(self.apr, self.parts, parts_pred)</code></pre>
</details>
</dd>
<dt id="pipapr.segmenter.tileTrainer.train_classifier"><code class="name flex">
<span>def <span class="ident">train_classifier</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Train the classifier for segmentation.</p>
<h2 id="parameters">Parameters</h2>
<p>verbose: (bool) option to print out information.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_classifier(self, verbose=True):
    &#34;&#34;&#34;
    Train the classifier for segmentation.

    Parameters
    ----------
    verbose: (bool) option to print out information.

    Returns
    -------
    None
    &#34;&#34;&#34;
    if self.pixel_list is None:
        raise ValueError(&#39;Error: annotate dataset or load annotations before training classifier.&#39;)

    from sklearn import preprocessing
    from sklearn.pipeline import make_pipeline
    from sklearn.ensemble import RandomForestClassifier

    # We sample pixel_list on APR grid
    self._sample_pixel_list_on_APR()

    # We remove ambiguous case where a particle was labeled differently
    self._remove_ambiguities(verbose=verbose)

    # We compute features and train the classifier
    if self.f is None:
        f = self.func_to_compute_features(self.apr, self.parts)

    # Fetch data that was manually labelled
    x = f[self.parts_train_idx]
    y = self.parts_labels

    # Train random forest
    clf = make_pipeline(preprocessing.StandardScaler(with_mean=True, with_std=True),
                        RandomForestClassifier(n_estimators=10, class_weight=&#39;balanced&#39;))
    t = time()
    clf.fit(x, y.ravel())
    print(&#39;Training took {} s.\n&#39;.format(time() - t))

    x_pred = clf.predict(x)

    # Display training info
    if verbose:
        print(&#39;\n****** TRAINING RESULTS ******&#39;)
        print(&#39;Total accuracy: {:0.2f}%&#39;.format(np.sum(x_pred == y) / y.size * 100))
        for l in self.unique_labels:
            print(&#39;Class {} accuracy: {:0.2f}% ({} cell particles)&#39;.format(l,
                np.sum((x_pred == y) * (y == l)) / np.sum(y == l) * 100, np.sum(y == l)))
        print(&#39;******************************\n&#39;)

    self.clf = clf
    self.f = f</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pipapr" href="index.html">pipapr</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pipapr.segmenter.map_feature" href="#pipapr.segmenter.map_feature">map_feature</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pipapr.segmenter.tileCells" href="#pipapr.segmenter.tileCells">tileCells</a></code></h4>
<ul class="">
<li><code><a title="pipapr.segmenter.tileCells.extract_and_merge_cells" href="#pipapr.segmenter.tileCells.extract_and_merge_cells">extract_and_merge_cells</a></code></li>
<li><code><a title="pipapr.segmenter.tileCells.save_cells" href="#pipapr.segmenter.tileCells.save_cells">save_cells</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pipapr.segmenter.tileSegmenter" href="#pipapr.segmenter.tileSegmenter">tileSegmenter</a></code></h4>
<ul class="">
<li><code><a title="pipapr.segmenter.tileSegmenter.compute_segmentation" href="#pipapr.segmenter.tileSegmenter.compute_segmentation">compute_segmentation</a></code></li>
<li><code><a title="pipapr.segmenter.tileSegmenter.from_classifier" href="#pipapr.segmenter.tileSegmenter.from_classifier">from_classifier</a></code></li>
<li><code><a title="pipapr.segmenter.tileSegmenter.from_trainer" href="#pipapr.segmenter.tileSegmenter.from_trainer">from_trainer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pipapr.segmenter.tileTrainer" href="#pipapr.segmenter.tileTrainer">tileTrainer</a></code></h4>
<ul class="">
<li><code><a title="pipapr.segmenter.tileTrainer.add_annotations" href="#pipapr.segmenter.tileTrainer.add_annotations">add_annotations</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.apply_on_tile" href="#pipapr.segmenter.tileTrainer.apply_on_tile">apply_on_tile</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.display_features" href="#pipapr.segmenter.tileTrainer.display_features">display_features</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.display_training_annotations" href="#pipapr.segmenter.tileTrainer.display_training_annotations">display_training_annotations</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.load_classifier" href="#pipapr.segmenter.tileTrainer.load_classifier">load_classifier</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.load_labels" href="#pipapr.segmenter.tileTrainer.load_labels">load_labels</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.manually_annotate" href="#pipapr.segmenter.tileTrainer.manually_annotate">manually_annotate</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.save_classifier" href="#pipapr.segmenter.tileTrainer.save_classifier">save_classifier</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.save_labels" href="#pipapr.segmenter.tileTrainer.save_labels">save_labels</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.segment_training_tile" href="#pipapr.segmenter.tileTrainer.segment_training_tile">segment_training_tile</a></code></li>
<li><code><a title="pipapr.segmenter.tileTrainer.train_classifier" href="#pipapr.segmenter.tileTrainer.train_classifier">train_classifier</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>